{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a264bdc49ea2966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T04:41:07.188098Z",
     "start_time": "2024-07-21T04:41:07.181097Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('D:\\ComputerScience\\Research\\PRADA\\sparse_autoencoder')\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# 导入库\n",
    "import torch\n",
    "import blobfile as bf\n",
    "import sparse_autoencoder\n",
    "from experiments.utils import update_json_file, update_numpy_file\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ae2db09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T04:44:57.804507Z",
     "start_time": "2024-07-21T04:44:57.786328Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "def load_model(model_name):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "    auto_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    gpt2_tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    return model, auto_tokenizer, gpt2_tokenizer, device\n",
    "\n",
    "# 处理输入\n",
    "def process_input(model, tokenizer, prompt):\n",
    "    tokens_id = tokenizer(prompt, return_tensors='pt').input_ids.to(model.device)\n",
    "    tokens_str = tokenizer.convert_ids_to_tokens(tokens_id[0])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_id)\n",
    "    activation_cache = outputs.hidden_states\n",
    "    return tokens_id, tokens_str, activation_cache\n",
    "\n",
    "# 提取激活\n",
    "def get_activation(activation_cache, layer_index=6, location=\"resid_post_mlp\"):\n",
    "    transformer_lens_loc = {\n",
    "        \"mlp_post_act\": f\"blocks.{layer_index}.mlp.hook_post\",\n",
    "        \"resid_delta_attn\": f\"blocks.{layer_index}.hook_attn_out\",\n",
    "        \"resid_post_attn\": f\"blocks.{layer_index}.hook_resid_mid\",\n",
    "        \"resid_delta_mlp\": f\"blocks.{layer_index}.hook_mlp_out\",\n",
    "        \"resid_post_mlp\": f\"blocks.{layer_index}.hook_resid_post\",\n",
    "    }[location]\n",
    "    return activation_cache[transformer_lens_loc]\n",
    "\n",
    "# 加载自编码器\n",
    "def load_autoencoder(location, layer_index, device):\n",
    "    with bf.BlobFile(sparse_autoencoder.paths.v5_128k(location, layer_index), mode=\"rb\") as f:\n",
    "        state_dict = torch.load(f)\n",
    "        autoencoder = sparse_autoencoder.Autoencoder.from_state_dict(state_dict)\n",
    "        autoencoder.to(device)\n",
    "    return autoencoder\n",
    "\n",
    "# 编码和解码激活张量\n",
    "def encode_decode(autoencoder, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        latent_activations, info = autoencoder.encode(input_tensor)\n",
    "        reconstructed_activations = autoencoder.decode(latent_activations, info)\n",
    "    return latent_activations, reconstructed_activations\n",
    "\n",
    "# 计算误差并打印结果\n",
    "def calculate_normalized_mse(input_tensor, reconstructed_activations):\n",
    "    normalized_mse = (reconstructed_activations - input_tensor).pow(2).sum(dim=1) / (input_tensor).pow(2).sum(dim=1)\n",
    "    return normalized_mse\n",
    "\n",
    "def extract_activations(prompt, tokens, latent_activations, top_k=32, activation_threshold=3):\n",
    "    activations_dict = {}\n",
    "    prompt_key = prompt  # 根据需要设置不同的 prompt 标识符\n",
    "\n",
    "    total_activations_count = 0\n",
    "    \n",
    "    # 遍历所有 feature\n",
    "    for feature_index in range(latent_activations.shape[1]):\n",
    "        # 获取该 feature 的所有激活值\n",
    "        feature_activations = latent_activations[:, feature_index]\n",
    "        \n",
    "        # 仅提取 top k 非零激活值\n",
    "        non_zero_activations = feature_activations[(feature_activations != 0) & (feature_activations >= activation_threshold)]\n",
    "        if non_zero_activations.numel() == 0:\n",
    "            continue\n",
    "        top_k_values, top_k_indices = torch.topk(non_zero_activations, min(top_k, non_zero_activations.numel()))\n",
    "\n",
    "        # 构建特征激活字典\n",
    "        feature_key = f\"Feature {feature_index}\"\n",
    "        activations_dict[feature_key] = {prompt_key: {}}\n",
    "        for value, index in zip(top_k_values, top_k_indices):\n",
    "            nonzero_indices = (feature_activations == value).nonzero(as_tuple=True)\n",
    "            if len(nonzero_indices[0]) == 1:  # 确保只有一个元素\n",
    "                token_index = nonzero_indices[0].item()\n",
    "                token = tokens[token_index]\n",
    "                activations_dict[feature_key][prompt][token] = [f\"idx:{token_index}\",value.item()]\n",
    "            else:\n",
    "                print(f\"Skipping ambiguous token index: {nonzero_indices}\")\n",
    "\n",
    "        total_activations_count += len(top_k_values)\n",
    "\n",
    "    # Print the total number of activations extracted\n",
    "    print(f\"Total activations extracted: {total_activations_count}\")\n",
    "\n",
    "    # Optionally, return the total number of activations\n",
    "    return activations_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d048903c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T04:38:54.429979Z",
     "start_time": "2024-07-21T04:38:09.129724Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "model, auto_tokenizer, gpt2_tokenizer, device = load_model(model_name)\n",
    "layer_index = 6\n",
    "location = \"resid_post_mlp\"\n",
    "autoencoder = load_autoencoder(location, layer_index, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153365d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T04:41:11.455888Z",
     "start_time": "2024-07-21T04:41:11.438762Z"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "output_folder = f'output/{today}'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86709e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens ID (AutoTokenizer): tensor([[   47,  1186,   437,   345,   821,   257, 18951, 13658,  1048,   284,\n",
      "          3280,   262,  1808,    13]])\n",
      "Tokens String (AutoTokenizer): ['P', 'ret', 'end', 'Ġyou', \"'re\", 'Ġa', 'Ġintro', 'verted', 'Ġperson', 'Ġto', 'Ġanswer', 'Ġthe', 'Ġquestion', '.']\n",
      "Tokens ID (GPT2Tokenizer): tensor([[   47,  1186,   437,   345,   821,   257, 18951, 13658,  1048,   284,\n",
      "          3280,   262,  1808,    13]])\n",
      "Tokens String (GPT2Tokenizer): ['P', 'ret', 'end', 'Ġyou', \"'re\", 'Ġa', 'Ġintro', 'verted', 'Ġperson', 'Ġto', 'Ġanswer', 'Ġthe', 'Ġquestion', '.']\n",
      "Number of layers in hidden_states: 13\n",
      "resid_post_mlp for layer 6: torch.Size([14, 768])\n",
      "tensor([[-7.2834e-01, -3.3760e+00,  9.7962e-01,  ..., -1.7737e+00,\n",
      "          1.3011e+00, -4.3048e-01],\n",
      "        [ 2.3055e+00,  1.3471e+00,  2.8651e+00,  ...,  1.6660e+00,\n",
      "         -4.2424e-01, -1.2197e+00],\n",
      "        [-2.5004e-01,  1.7333e+00, -1.1717e+00,  ...,  9.8642e-01,\n",
      "          3.5260e+00, -1.0241e+00],\n",
      "        ...,\n",
      "        [ 1.0971e-01,  2.2309e+00, -3.0276e+00,  ...,  3.1990e-03,\n",
      "          2.5980e-01, -2.7361e+00],\n",
      "        [ 1.4341e+00,  1.2202e+00, -4.3185e+00,  ...,  3.9609e+00,\n",
      "         -1.8932e+00, -1.3063e+00],\n",
      "        [ 9.1736e-02, -1.8090e+00, -1.5026e+00,  ..., -1.5290e+00,\n",
      "          1.0528e-01, -1.0346e+00]])\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Pretend you\\'re a introverted person to answer the question.'\n",
    "# 使用 AutoTokenizer\n",
    "tokens_id_auto, tokens_str_auto, activation_cache_auto = process_input(model, auto_tokenizer, prompt)\n",
    "# 使用 GPT2Tokenizer\n",
    "tokens_id_gpt2, tokens_str_gpt2, activation_cache_gpt2 = process_input(model, gpt2_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id_auto)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str_auto)\n",
    "# 打印hidden_states信息，确保正确提取\n",
    "if activation_cache_auto is not None:\n",
    "    print(f\"Number of layers in hidden_states: {len(activation_cache_auto)}\")\n",
    "else:\n",
    "    print(\"No hidden_states found.\")\n",
    "\n",
    "resid_post_mlp = activation_cache_auto[layer_index+1]\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", resid_post_mlp[0].shape if resid_post_mlp is not None else \"None\")\n",
    "print(resid_post_mlp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f829e42434afbfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T05:23:23.920463Z",
     "start_time": "2024-07-21T04:44:59.494797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([57, 131072])\n",
      "torch.Size([1, 57, 768])\n",
      "torch.Size([57, 768])\n",
      "Non-zero activation count: 1823\n",
      "This is 1/50 prompt\n",
      "Total activations extracted: 201\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([94, 131072])\n",
      "torch.Size([1, 94, 768])\n",
      "torch.Size([94, 768])\n",
      "Non-zero activation count: 3007\n",
      "This is 2/50 prompt\n",
      "Total activations extracted: 313\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([122, 131072])\n",
      "torch.Size([1, 122, 768])\n",
      "torch.Size([122, 768])\n",
      "Non-zero activation count: 3903\n",
      "This is 3/50 prompt\n",
      "Total activations extracted: 407\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([135, 131072])\n",
      "torch.Size([1, 135, 768])\n",
      "torch.Size([135, 768])\n",
      "Non-zero activation count: 4319\n",
      "This is 4/50 prompt\n",
      "Total activations extracted: 443\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([138, 131072])\n",
      "torch.Size([1, 138, 768])\n",
      "torch.Size([138, 768])\n",
      "Non-zero activation count: 4415\n",
      "This is 5/50 prompt\n",
      "Total activations extracted: 432\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([74, 131072])\n",
      "torch.Size([1, 74, 768])\n",
      "torch.Size([74, 768])\n",
      "Non-zero activation count: 2367\n",
      "This is 6/50 prompt\n",
      "Total activations extracted: 254\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([129, 131072])\n",
      "torch.Size([1, 129, 768])\n",
      "torch.Size([129, 768])\n",
      "Non-zero activation count: 4127\n",
      "This is 7/50 prompt\n",
      "Total activations extracted: 430\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([110, 131072])\n",
      "torch.Size([1, 110, 768])\n",
      "torch.Size([110, 768])\n",
      "Non-zero activation count: 3519\n",
      "This is 8/50 prompt\n",
      "Total activations extracted: 336\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([131, 131072])\n",
      "torch.Size([1, 131, 768])\n",
      "torch.Size([131, 768])\n",
      "Non-zero activation count: 4191\n",
      "This is 9/50 prompt\n",
      "Total activations extracted: 479\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([82, 131072])\n",
      "torch.Size([1, 82, 768])\n",
      "torch.Size([82, 768])\n",
      "Non-zero activation count: 2623\n",
      "This is 10/50 prompt\n",
      "Total activations extracted: 292\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([100, 131072])\n",
      "torch.Size([1, 100, 768])\n",
      "torch.Size([100, 768])\n",
      "Non-zero activation count: 3199\n",
      "This is 11/50 prompt\n",
      "Total activations extracted: 327\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([134, 131072])\n",
      "torch.Size([1, 134, 768])\n",
      "torch.Size([134, 768])\n",
      "Non-zero activation count: 4287\n",
      "This is 12/50 prompt\n",
      "Total activations extracted: 469\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([193, 131072])\n",
      "torch.Size([1, 193, 768])\n",
      "torch.Size([193, 768])\n",
      "Non-zero activation count: 6175\n",
      "This is 13/50 prompt\n",
      "Total activations extracted: 605\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([167, 131072])\n",
      "torch.Size([1, 167, 768])\n",
      "torch.Size([167, 768])\n",
      "Non-zero activation count: 5343\n",
      "This is 14/50 prompt\n",
      "Total activations extracted: 569\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([149, 131072])\n",
      "torch.Size([1, 149, 768])\n",
      "torch.Size([149, 768])\n",
      "Non-zero activation count: 4767\n",
      "This is 15/50 prompt\n",
      "Total activations extracted: 452\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([45, 131072])\n",
      "torch.Size([1, 45, 768])\n",
      "torch.Size([45, 768])\n",
      "Non-zero activation count: 1439\n",
      "This is 16/50 prompt\n",
      "Total activations extracted: 160\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([129, 131072])\n",
      "torch.Size([1, 129, 768])\n",
      "torch.Size([129, 768])\n",
      "Non-zero activation count: 4127\n",
      "This is 17/50 prompt\n",
      "Total activations extracted: 386\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([145, 131072])\n",
      "torch.Size([1, 145, 768])\n",
      "torch.Size([145, 768])\n",
      "Non-zero activation count: 4639\n",
      "This is 18/50 prompt\n",
      "Total activations extracted: 471\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([130, 131072])\n",
      "torch.Size([1, 130, 768])\n",
      "torch.Size([130, 768])\n",
      "Non-zero activation count: 4159\n",
      "This is 19/50 prompt\n",
      "Total activations extracted: 398\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([126, 131072])\n",
      "torch.Size([1, 126, 768])\n",
      "torch.Size([126, 768])\n",
      "Non-zero activation count: 4031\n",
      "This is 20/50 prompt\n",
      "Total activations extracted: 436\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([142, 131072])\n",
      "torch.Size([1, 142, 768])\n",
      "torch.Size([142, 768])\n",
      "Non-zero activation count: 4543\n",
      "This is 21/50 prompt\n",
      "Total activations extracted: 444\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([111, 131072])\n",
      "torch.Size([1, 111, 768])\n",
      "torch.Size([111, 768])\n",
      "Non-zero activation count: 3551\n",
      "This is 22/50 prompt\n",
      "Total activations extracted: 375\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([85, 131072])\n",
      "torch.Size([1, 85, 768])\n",
      "torch.Size([85, 768])\n",
      "Non-zero activation count: 2719\n",
      "This is 23/50 prompt\n",
      "Total activations extracted: 306\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([204, 131072])\n",
      "torch.Size([1, 204, 768])\n",
      "torch.Size([204, 768])\n",
      "Non-zero activation count: 6527\n",
      "This is 24/50 prompt\n",
      "Total activations extracted: 693\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([166, 131072])\n",
      "torch.Size([1, 166, 768])\n",
      "torch.Size([166, 768])\n",
      "Non-zero activation count: 5311\n",
      "This is 25/50 prompt\n",
      "Total activations extracted: 519\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([148, 131072])\n",
      "torch.Size([1, 148, 768])\n",
      "torch.Size([148, 768])\n",
      "Non-zero activation count: 4735\n",
      "This is 26/50 prompt\n",
      "Total activations extracted: 499\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([36, 131072])\n",
      "torch.Size([1, 36, 768])\n",
      "torch.Size([36, 768])\n",
      "Non-zero activation count: 1151\n",
      "This is 27/50 prompt\n",
      "Total activations extracted: 117\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([149, 131072])\n",
      "torch.Size([1, 149, 768])\n",
      "torch.Size([149, 768])\n",
      "Non-zero activation count: 4767\n",
      "This is 28/50 prompt\n",
      "Total activations extracted: 491\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([123, 131072])\n",
      "torch.Size([1, 123, 768])\n",
      "torch.Size([123, 768])\n",
      "Non-zero activation count: 3935\n",
      "This is 29/50 prompt\n",
      "Total activations extracted: 390\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([85, 131072])\n",
      "torch.Size([1, 85, 768])\n",
      "torch.Size([85, 768])\n",
      "Non-zero activation count: 2719\n",
      "This is 30/50 prompt\n",
      "Total activations extracted: 304\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([90, 131072])\n",
      "torch.Size([1, 90, 768])\n",
      "torch.Size([90, 768])\n",
      "Non-zero activation count: 2879\n",
      "This is 31/50 prompt\n",
      "Total activations extracted: 299\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([76, 131072])\n",
      "torch.Size([1, 76, 768])\n",
      "torch.Size([76, 768])\n",
      "Non-zero activation count: 2431\n",
      "This is 32/50 prompt\n",
      "Total activations extracted: 270\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([44, 131072])\n",
      "torch.Size([1, 44, 768])\n",
      "torch.Size([44, 768])\n",
      "Non-zero activation count: 1407\n",
      "This is 33/50 prompt\n",
      "Total activations extracted: 135\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([104, 131072])\n",
      "torch.Size([1, 104, 768])\n",
      "torch.Size([104, 768])\n",
      "Non-zero activation count: 3327\n",
      "This is 34/50 prompt\n",
      "Total activations extracted: 402\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([114, 131072])\n",
      "torch.Size([1, 114, 768])\n",
      "torch.Size([114, 768])\n",
      "Non-zero activation count: 3647\n",
      "This is 35/50 prompt\n",
      "Total activations extracted: 372\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([155, 131072])\n",
      "torch.Size([1, 155, 768])\n",
      "torch.Size([155, 768])\n",
      "Non-zero activation count: 4959\n",
      "This is 36/50 prompt\n",
      "Total activations extracted: 523\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([52, 131072])\n",
      "torch.Size([1, 52, 768])\n",
      "torch.Size([52, 768])\n",
      "Non-zero activation count: 1663\n",
      "This is 37/50 prompt\n",
      "Total activations extracted: 171\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([166, 131072])\n",
      "torch.Size([1, 166, 768])\n",
      "torch.Size([166, 768])\n",
      "Non-zero activation count: 5311\n",
      "This is 38/50 prompt\n",
      "Total activations extracted: 519\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([46, 131072])\n",
      "torch.Size([1, 46, 768])\n",
      "torch.Size([46, 768])\n",
      "Non-zero activation count: 1471\n",
      "This is 39/50 prompt\n",
      "Total activations extracted: 156\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([47, 131072])\n",
      "torch.Size([1, 47, 768])\n",
      "torch.Size([47, 768])\n",
      "Non-zero activation count: 1503\n",
      "This is 40/50 prompt\n",
      "Total activations extracted: 159\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([167, 131072])\n",
      "torch.Size([1, 167, 768])\n",
      "torch.Size([167, 768])\n",
      "Non-zero activation count: 5343\n",
      "This is 41/50 prompt\n",
      "Total activations extracted: 562\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([150, 131072])\n",
      "torch.Size([1, 150, 768])\n",
      "torch.Size([150, 768])\n",
      "Non-zero activation count: 4799\n",
      "This is 42/50 prompt\n",
      "Total activations extracted: 521\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([127, 131072])\n",
      "torch.Size([1, 127, 768])\n",
      "torch.Size([127, 768])\n",
      "Non-zero activation count: 4063\n",
      "This is 43/50 prompt\n",
      "Total activations extracted: 420\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([131, 131072])\n",
      "torch.Size([1, 131, 768])\n",
      "torch.Size([131, 768])\n",
      "Non-zero activation count: 4191\n",
      "This is 44/50 prompt\n",
      "Total activations extracted: 441\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([134, 131072])\n",
      "torch.Size([1, 134, 768])\n",
      "torch.Size([134, 768])\n",
      "Non-zero activation count: 4287\n",
      "This is 45/50 prompt\n",
      "Total activations extracted: 449\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([111, 131072])\n",
      "torch.Size([1, 111, 768])\n",
      "torch.Size([111, 768])\n",
      "Non-zero activation count: 3551\n",
      "This is 46/50 prompt\n",
      "Total activations extracted: 364\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([69, 131072])\n",
      "torch.Size([1, 69, 768])\n",
      "torch.Size([69, 768])\n",
      "Non-zero activation count: 2207\n",
      "This is 47/50 prompt\n",
      "Total activations extracted: 239\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([41, 131072])\n",
      "torch.Size([1, 41, 768])\n",
      "torch.Size([41, 768])\n",
      "Non-zero activation count: 1311\n",
      "This is 48/50 prompt\n",
      "Total activations extracted: 128\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([53, 131072])\n",
      "torch.Size([1, 53, 768])\n",
      "torch.Size([53, 768])\n",
      "Non-zero activation count: 1695\n",
      "This is 49/50 prompt\n",
      "Total activations extracted: 182\n",
      "current file: dataset/prompt_1000_pro_2\\energy_introversion.parquet\n",
      "torch.Size([78, 131072])\n",
      "torch.Size([1, 78, 768])\n",
      "torch.Size([78, 768])\n",
      "Non-zero activation count: 2495\n",
      "This is 50/50 prompt\n",
      "Total activations extracted: 279\n"
     ]
    }
   ],
   "source": [
    "# 设置路径\n",
    "prompt_folder_path = 'dataset/prompt_1000_pro_2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 遍历所有 .parquet 文件\n",
    "for file_name in os.listdir(prompt_folder_path):\n",
    "    count = 1\n",
    "    if file_name.endswith('.parquet'):\n",
    "        prompt_file_path = os.path.join(prompt_folder_path, file_name)\n",
    "        data = pd.read_parquet(prompt_file_path)\n",
    "        data = data[:50]\n",
    "        for index, row in data.iterrows():\n",
    "            print(f\"current file: {prompt_file_path}\")\n",
    "            prompt_id = row['prompt_id']\n",
    "            prompt = row['prompt']\n",
    "            tokens_id, tokens_str, activation_cache = process_input(model, tokenizer, prompt)\n",
    "            activation = activation_cache[layer_index+1]\n",
    "            latent_activations, reconstructed_activations = encode_decode(autoencoder, activation[0])\n",
    "\n",
    "            print(latent_activations.shape)\n",
    "            print(activation[0].shape)\n",
    "            print(reconstructed_activations.shape)\n",
    "            non_zero_count = (latent_activations != 0).sum().item()\n",
    "            print(\"Non-zero activation count:\", non_zero_count)\n",
    "            print(f\"This is {count}/50 prompt\")\n",
    "            count+=1\n",
    "            activations_dict = extract_activations(prompt_id, tokens_str, latent_activations, top_k=5)\n",
    "            \n",
    "            activations_file_name = file_name.replace('.parquet', '_1000_activation_pro_2_128k.json')\n",
    "            activations_file_path = os.path.join(output_folder, activations_file_name)\n",
    "            \n",
    "            update_json_file(activations_file_path, activations_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
