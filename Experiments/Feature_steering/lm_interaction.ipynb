{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('D:\\ComputerScience\\Research\\PRADA\\sparse_autoencoder')\n",
    "# 导入库\n",
    "import torch\n",
    "import blobfile as bf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are you introverted?\n",
      "GPT-2 Response: Are you introverted?\n",
      "\n",
      "I'm not. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert\n",
      "\n",
      "Question: Do you prefer spending time alone or with others?\n",
      "GPT-2 Response: Do you prefer spending time alone or with others?\n",
      "\n",
      "I prefer to spend time with others. I like to spend time with myself. I like to spend time with myself. I like to spend time with myself. I like to spend time with\n",
      "\n",
      "Question: How do you feel about going to large social gatherings?\n",
      "GPT-2 Response: How do you feel about going to large social gatherings?\n",
      "\n",
      "I think it's a good idea to have a lot of people there. I think it's a good idea to have a lot of people there. I think it's a good idea\n",
      "\n",
      "Question: Do you find it easy to start conversations with strangers?\n",
      "GPT-2 Response: Do you find it easy to start conversations with strangers?\n",
      "\n",
      "I think it's a good thing. I think it's a good thing that people are willing to talk to me. I think it's a good thing that people are willing to talk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "# 定义加载模型的函数\n",
    "def load_model(model_name):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer, device\n",
    "\n",
    "# 定义对话函数\n",
    "def chat_with_gpt2(model, tokenizer, device, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs.input_ids, max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "model, tokenizer, device = load_model(model_name)\n",
    "\n",
    "introverted_questions = [\n",
    "    \"Are you introverted?\",\n",
    "    \"Do you prefer spending time alone or with others?\",\n",
    "    \"How do you feel about going to large social gatherings?\",\n",
    "    \"Do you find it easy to start conversations with strangers?\",\n",
    "]\n",
    "\n",
    "# 获取并打印GPT-2的回答\n",
    "for question in introverted_questions:\n",
    "    response = chat_with_gpt2(model, tokenizer, device, question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"GPT-2 Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e8f99fc4b0440f8bdad873127f3d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do you prefer spending time alone or with others?\n",
      "GPT-2 Response: ['<|endoftext|>Do you prefer spending time alone or with others? Please rate the User Experience and Services\\n\\nHow apply rates apply\\n\\nDisplay form Send a letter to user forcing process\\n\\nWhy does termination entail a termination hearing? Termination terms and conditions may already be ready to be available\\n\\nHow do']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f333d48f3f49b1a8fa4ba885748e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How do you feel about going to large social gatherings?\n",
      "GPT-2 Response: ['<|endoftext|>How do you feel about going to large social gatherings?\\n\\n— Lem in Paris\\n\\nRead The Evening Sun\\n\\nEat Like France\\n\\nYou need an RSS Feed to reader for this piece.\\n\\nGet contribute, and publicize this piece via social media.\\n\\nShare this: Twitter']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bb50ddffc34ff7a736842980fa56c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do you find it easy to start conversations with strangers?\n",
      "GPT-2 Response: [\"<|endoftext|>Do you find it easy to start conversations with strangers? Surrounded by strangers, do you trust people more? Happily, strangers not only have answers to your questions, they offer them context as well. Ask my parents, and they'll give you something to talk about once they're gone.\\n\\n\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments.utils import *\n",
    "def chat_with_gpt2(model, prompt):\n",
    "    tokens_id, tokens_str, activation_cache = process_input(model, prompt)\n",
    "    # 使用模型生成输出\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(tokens_id, max_new_tokens=50)\n",
    "    # 将生成的令牌转换回字符串\n",
    "    output_text = model.to_string(output_ids)\n",
    "    return output_text\n",
    "model_name = \"gpt2\"\n",
    "model, device = load_model(model_name)\n",
    "\n",
    "introverted_questions = [\n",
    "    \"Do you prefer spending time alone or with others?\",\n",
    "    \"How do you feel about going to large social gatherings?\",\n",
    "    \"Do you find it easy to start conversations with strangers?\",\n",
    "]\n",
    "\n",
    "# 获取并打印GPT-2的回答\n",
    "for question in introverted_questions:\n",
    "    response = chat_with_gpt2(model, question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"GPT-2 Response: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
