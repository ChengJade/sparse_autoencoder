{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:02:50.010183Z",
     "start_time": "2024-07-22T20:02:43.397665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('D:\\ComputerScience\\Research\\PRADA\\sparse_autoencoder')\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# 导入库\n",
    "import torch\n",
    "import blobfile as bf\n",
    "from experiments.utils import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, GPT2Tokenizer, GPT2Config, set_seed, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d299df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SAE from: az://openaipublic/sparse-autoencoder/gpt2-small/resid_post_mlp_v5_32k/autoencoders/6.pt\n",
      "State dictionary saved to model/gpt2_sae/sae_state_32k_layer_6.pt\n",
      "Downloading SAE from: az://openaipublic/sparse-autoencoder/gpt2-small/resid_post_mlp_v5_128k/autoencoders/6.pt\n",
      "State dictionary saved to model/gpt2_sae/sae_state_128k_layer_6.pt\n"
     ]
    }
   ],
   "source": [
    "# 下载AutoEncoder\n",
    "position = \"resid_post_mlp\"\n",
    "layer_index = 6\n",
    "download_autoencoder(position, layer_index=layer_index, size=32)\n",
    "download_autoencoder(position, layer_index=layer_index, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a9f3b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_steering(autoencoder,x: torch.Tensor, feature_indices: list[int], feature_values: list[float]) -> torch.Tensor:\n",
    "    assert len(feature_indices) == len(feature_values), \"Feature indices and values must have the same length.\"\n",
    "    # feature_values = [max(min(value, 10), -10) for value in feature_values]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 获取原始特征表示和信息\n",
    "        latents, info = autoencoder.encode(x)\n",
    "        # 修改特征表示\n",
    "        for index, value in zip(feature_indices, feature_values):\n",
    "            print(\"original:\", latents[:, index])\n",
    "            if value > 0:\n",
    "                latents[:, index] *= value\n",
    "            else:\n",
    "                latents[:, index] = latents[:, index] / abs(value)\n",
    "            print(\"Modified:\", latents[:, index])\n",
    "            print(f\"Feature {index} modified with {'+' if value >= 0 else ''}{value}\")\n",
    "        # 使用修改后的特征表示通过解码器生成重构输出\n",
    "        modified_output = autoencoder.decode(latents, info)\n",
    "    return modified_output\n",
    "\n",
    "def calculate_error(input_tensor, reconstructed_activations) -> torch.Tensor:\n",
    "    # 计算误差\n",
    "    error = input_tensor - reconstructed_activations\n",
    "    # 可以选择使用不同的误差度量方式，这里使用均方误差（MSE）\n",
    "    normalized_mse = (reconstructed_activations - input_tensor).pow(2).sum(dim=1) / (input_tensor).pow(2).sum(dim=1)\n",
    "    return normalized_mse, error\n",
    "\n",
    "\n",
    "def compare_activations(tensor1, tensor2):\n",
    "    difference = tensor1 - tensor2\n",
    "    print(\"Difference between tensors:\\n\", difference)\n",
    "\n",
    "    # 计算差异的统计信息\n",
    "    mean_diff = torch.mean(difference)\n",
    "    std_diff = torch.std(difference)\n",
    "    print(f\"Mean difference: {mean_diff.item()}\")\n",
    "    print(f\"Standard deviation of difference: {std_diff.item()}\")\n",
    "\n",
    "    # 可视化差异\n",
    "    difference_np = difference.numpy()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.imshow(difference_np, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar(label='Difference')\n",
    "    plt.title('Difference between Reconstructed Activations and Modified Output')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Sample Index')\n",
    "    plt.show()\n",
    "\n",
    "def chat_with_gpt2_logits(model, tokens_id, tokenizer):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_id)\n",
    "        logits = outputs.logits\n",
    "        # 使用torch.argmax选出概率最高的token ids\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        # 解码生成的token ids\n",
    "        response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    return response, logits\n",
    "\n",
    "def chat_with_gpt2_top_k_candidates(model, tokens_id, tokenizer, top_k=10):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_id)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # 选择每个时间步上概率最高的top_k个token的logits\n",
    "        top_k_logits, top_k_indices = torch.topk(logits, k=top_k, dim=-1)\n",
    "        \n",
    "        # 解码每个token的索引以获取token字符串\n",
    "        top_k_tokens = [\n",
    "            [tokenizer.decode([idx]) for idx in indices[0]] for indices in top_k_indices\n",
    "        ]\n",
    "\n",
    "    for step in range(logits.shape[1]):  # 限制打印至最多前10个token\n",
    "            print(f\"Step {step + 1}:\")\n",
    "            for i in range(top_k):\n",
    "                token = tokenizer.decode([top_k_indices[0, step, i]])\n",
    "                logit = top_k_logits[0, step, i].item()\n",
    "                print(f\"  Candidate {i + 1}: {token} (Logit: {logit})\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "    return top_k_tokens, top_k_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5bb1aac7ca685e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:03:05.660715Z",
     "start_time": "2024-07-22T20:02:50.012200Z"
    }
   },
   "outputs": [],
   "source": [
    "model, auto_tokenizer, device = load_model_hf(\"gpt2\")\n",
    "layer_index = 6\n",
    "autoencoder = load_autoencoder_from_local(layer_index, device, 128)\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ebf18",
   "metadata": {},
   "source": [
    "# Activation Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b49ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprompt = \"Are you introverted?\"\\nfeature_indices = [53912]\\nfeature_values = [10] \\ntokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\\nprint(\"Tokens ID (AutoTokenizer):\", tokens_id)\\nprint(\"Tokens String (AutoTokenizer):\", tokens_str)\\nprint(len(activation_cache))\\nactivation = get_activation_hf(activation_cache, layer_index)\\nprint(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\\nprint(activation)\\n\\nlatent_activations, recon_activations = encode_decode(autoencoder, activation)\\nmse_error, error = calculate_error(activation, recon_activations)\\n\\nmodified_recon_activations = feature_steering(autoencoder, activation, feature_indices, feature_values)\\nprint(\"orginal modified_recon_activations:\", modified_recon_activations)\\nprint(modified_recon_activations.shape)\\n\\nmodified_recon_activations_new = modified_recon_activations + error\\nprint(\"modified_recon_activations + error:\", modified_recon_activations_new)\\n\\nmse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\\nprint(error_after)\\nprint(mse_error_after)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "prompt = \"Are you introverted?\"\n",
    "feature_indices = [53912]\n",
    "feature_values = [10] \n",
    "tokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str)\n",
    "print(len(activation_cache))\n",
    "activation = get_activation_hf(activation_cache, layer_index)\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\n",
    "print(activation)\n",
    "\n",
    "latent_activations, recon_activations = encode_decode(autoencoder, activation)\n",
    "mse_error, error = calculate_error(activation, recon_activations)\n",
    "\n",
    "modified_recon_activations = feature_steering(autoencoder, activation, feature_indices, feature_values)\n",
    "print(\"orginal modified_recon_activations:\", modified_recon_activations)\n",
    "print(modified_recon_activations.shape)\n",
    "\n",
    "modified_recon_activations_new = modified_recon_activations + error\n",
    "print(\"modified_recon_activations + error:\", modified_recon_activations_new)\n",
    "\n",
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(error_after)\n",
    "print(mse_error_after)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e45a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "Tokens ID (AutoTokenizer): tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "Tokens String (AutoTokenizer): ['Are', 'Ġyou', 'Ġintro', 'verted', '?']\n",
      "13\n",
      "resid_post_mlp for layer 6: torch.Size([5, 768])\n",
      "tensor([[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "        [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "        [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "        [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "        [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 提取原始第六层\n",
    "prompt = \"Are you introverted?\"\n",
    "tokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str)\n",
    "print(len(activation_cache))\n",
    "activation = get_activation_hf(activation_cache, layer_index)\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\n",
    "print(activation)\n",
    "modified_recon_activations_new = activation\n",
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(error_after)\n",
    "print(mse_error_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c0653",
   "metadata": {},
   "source": [
    "### Original Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5454c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "input_id tensor([[198]])\n",
      "input_id tensor([[198]])\n",
      "input_id tensor([[40]])\n",
      "input_id tensor([[1101]])\n",
      "input_id tensor([[407]])\n",
      "input_id tensor([[13]])\n",
      "input_id tensor([[314]])\n",
      "input_id tensor([[1101]])\n",
      "input_id tensor([[407]])\n",
      "input_id tensor([[257]])\n",
      "input_id tensor([[1263]])\n",
      "input_id tensor([[18951]])\n",
      "input_id tensor([[1851]])\n",
      "input_id tensor([[13]])\n",
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "Step 1:\n",
      "  Candidate 1:  the (Logit: -29.919225692749023)\n",
      "  Candidate 2:  a (Logit: -30.52708625793457)\n",
      "  Candidate 3:  to (Logit: -30.872114181518555)\n",
      "  Candidate 4: , (Logit: -31.00540542602539)\n",
      "  Candidate 5: \n",
      " (Logit: -31.133556365966797)\n",
      "  Candidate 6:  you (Logit: -31.3023681640625)\n",
      "  Candidate 7: . (Logit: -31.325265884399414)\n",
      "  Candidate 8:  in (Logit: -31.418594360351562)\n",
      "  Candidate 9:  that (Logit: -31.46228790283203)\n",
      "  Candidate 10:  it (Logit: -31.574438095092773)\n",
      "\n",
      "\n",
      "Step 2:\n",
      "  Candidate 1:  a (Logit: -119.24163055419922)\n",
      "  Candidate 2:  sure (Logit: -119.3289794921875)\n",
      "  Candidate 3:  going (Logit: -119.41527557373047)\n",
      "  Candidate 4:  ready (Logit: -119.50484466552734)\n",
      "  Candidate 5:  looking (Logit: -120.21627807617188)\n",
      "  Candidate 6:  still (Logit: -120.2265396118164)\n",
      "  Candidate 7:  interested (Logit: -120.4596176147461)\n",
      "  Candidate 8:  using (Logit: -120.46378326416016)\n",
      "  Candidate 9:  in (Logit: -120.65441131591797)\n",
      "  Candidate 10:  worried (Logit: -120.6690444946289)\n",
      "\n",
      "\n",
      "Step 3:\n",
      "  Candidate 1: verted (Logit: -51.58854675292969)\n",
      "  Candidate 2: spective (Logit: -53.28206253051758)\n",
      "  Candidate 3: spect (Logit: -54.37642288208008)\n",
      "  Candidate 4: vert (Logit: -54.5172119140625)\n",
      "  Candidate 5: verts (Logit: -55.68467712402344)\n",
      "  Candidate 6: spection (Logit: -57.39292526245117)\n",
      "  Candidate 7: ? (Logit: -57.74125289916992)\n",
      "  Candidate 8: version (Logit: -57.999237060546875)\n",
      "  Candidate 9:  to (Logit: -58.08490753173828)\n",
      "  Candidate 10: - (Logit: -58.32606887817383)\n",
      "\n",
      "\n",
      "Step 4:\n",
      "  Candidate 1: ? (Logit: -74.06855010986328)\n",
      "  Candidate 2: , (Logit: -75.42339324951172)\n",
      "  Candidate 3: ?\" (Logit: -75.49243927001953)\n",
      "  Candidate 4:  or (Logit: -75.92665100097656)\n",
      "  Candidate 5:  and (Logit: -76.72173309326172)\n",
      "  Candidate 6:  enough (Logit: -77.468994140625)\n",
      "  Candidate 7:  yet (Logit: -77.6148452758789)\n",
      "  Candidate 8:  like (Logit: -78.0799789428711)\n",
      "  Candidate 9:  at (Logit: -78.23387908935547)\n",
      "  Candidate 10:  in (Logit: -78.2605209350586)\n",
      "\n",
      "\n",
      "Step 5:\n",
      "  Candidate 1: \n",
      " (Logit: -124.7516098022461)\n",
      "  Candidate 2:  Do (Logit: -126.13678741455078)\n",
      "  Candidate 3:  I (Logit: -126.33380889892578)\n",
      "  Candidate 4:  You (Logit: -126.39299774169922)\n",
      "  Candidate 5:  If (Logit: -126.39952850341797)\n",
      "  Candidate 6:  Are (Logit: -126.61884307861328)\n",
      "  Candidate 7:  What (Logit: -126.8447265625)\n",
      "  Candidate 8:  How (Logit: -126.89637756347656)\n",
      "  Candidate 9:  Then (Logit: -127.16068267822266)\n",
      "  Candidate 10:  Or (Logit: -127.1952133178711)\n",
      "\n",
      "\n",
      "Original Output: Are you introverted?\n",
      "\n",
      "I'm not. I'm not a big introvert. I\n",
      "logits type Output:  the averted?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat_with_gpt2(model, tokens_id):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(tokens_id, max_length=20, pad_token_id=auto_tokenizer.eos_token_id)\n",
    "    response = auto_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "response = chat_with_gpt2(model, tokens_id)\n",
    "response_l, logits = chat_with_gpt2_logits(model, tokens_id, auto_tokenizer)\n",
    "chat_with_gpt2_top_k_candidates(model, tokens_id, auto_tokenizer)\n",
    "print(\"Original Output:\", response)\n",
    "print(\"logits type Output:\", response_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f10ca",
   "metadata": {},
   "source": [
    "### Controlled Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "443b2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "torch.Size([1, 5, 768])\n",
      "tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "['Are', 'Ġyou', 'Ġintro', 'verted', '?']\n"
     ]
    }
   ],
   "source": [
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(mse_error_after)\n",
    "modified_activations = modified_recon_activations_new.unsqueeze(0)\n",
    "print(modified_activations.shape)\n",
    "print(modified_activations)\n",
    "print(tokens_id)\n",
    "print(tokens_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c43646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from torch import nn\n",
    "class ModifiedGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.modified_output = None  # 用于存储第六层的原始输出\n",
    "        self.temp = GPT2Model(config=config)\n",
    "        self.ln_f = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        \n",
    "    def set_modified_output(self, output, layer_to_modify=6):\n",
    "        self.modified_output = output\n",
    "        self.layer_to_modify = layer_to_modify\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, output_hidden_states=True, **kwargs):\n",
    "        print(\"input_shape:\", input_ids)\n",
    "        output = self.transformer(input_ids, output_hidden_states=True, **kwargs)\n",
    "        # output = super().forward(input_ids, output_hidden_states=True, **kwargs)\n",
    "        hidden_states = output[0]\n",
    "        logits_before = self.lm_head(hidden_states)\n",
    "        print(\"original final state:\", hidden_states)\n",
    "        print(\"before shape:\", logits_before.shape)\n",
    "        print(\"before:\", logits_before)\n",
    "        # 继续通过剩余的层\n",
    "        if self.modified_output is not None:\n",
    "            # 从指定层开始使用提供的激活值进行修改\n",
    "            modified_states = self.modified_output\n",
    "            for i in range(self.layer_to_modify, len(self.transformer.h)):\n",
    "                print(f\"Layer {i} original activation:\", output[2][i])\n",
    "                layer_module = self.transformer.h[i]\n",
    "                print(f\"Layer {i} modified activation:\", modified_states)\n",
    "                layer_outputs = layer_module(modified_states, attention_mask=None)  \n",
    "                modified_states = layer_outputs[0]\n",
    "                print(f\"Layer {i+1} pre-view activation:\", modified_states)\n",
    "            # 将最终输出设置为最后一层修改后的输出\n",
    "            hidden_states = modified_states\n",
    "            print(\"final state original after ln_f: \", output[2][12] )\n",
    "            print(\"final state modified before ln_f: \", hidden_states)\n",
    "            hidden_states = self.ln_f(hidden_states)\n",
    "            print(\"final state modified after ln_f: \", hidden_states)\n",
    "            # print(\"error:\",calculate_error(output[2][12], hidden_states))\n",
    "        # 输出最后一层的hidden state给LM头\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        #print(\"after shape:\", logits.shape)\n",
    "        #print(\"after:\", logits)\n",
    "        #mse, error = calculate_error(logits, logits_before)\n",
    "        #print(\"error:\",error)\n",
    "        return CausalLMOutputWithPast(logits=logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1352a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModifiedGPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['temp.h.0.attn.c_attn.bias', 'temp.h.0.attn.c_attn.weight', 'temp.h.0.attn.c_proj.bias', 'temp.h.0.attn.c_proj.weight', 'temp.h.0.ln_1.bias', 'temp.h.0.ln_1.weight', 'temp.h.0.ln_2.bias', 'temp.h.0.ln_2.weight', 'temp.h.0.mlp.c_fc.bias', 'temp.h.0.mlp.c_fc.weight', 'temp.h.0.mlp.c_proj.bias', 'temp.h.0.mlp.c_proj.weight', 'temp.h.1.attn.c_attn.bias', 'temp.h.1.attn.c_attn.weight', 'temp.h.1.attn.c_proj.bias', 'temp.h.1.attn.c_proj.weight', 'temp.h.1.ln_1.bias', 'temp.h.1.ln_1.weight', 'temp.h.1.ln_2.bias', 'temp.h.1.ln_2.weight', 'temp.h.1.mlp.c_fc.bias', 'temp.h.1.mlp.c_fc.weight', 'temp.h.1.mlp.c_proj.bias', 'temp.h.1.mlp.c_proj.weight', 'temp.h.10.attn.c_attn.bias', 'temp.h.10.attn.c_attn.weight', 'temp.h.10.attn.c_proj.bias', 'temp.h.10.attn.c_proj.weight', 'temp.h.10.ln_1.bias', 'temp.h.10.ln_1.weight', 'temp.h.10.ln_2.bias', 'temp.h.10.ln_2.weight', 'temp.h.10.mlp.c_fc.bias', 'temp.h.10.mlp.c_fc.weight', 'temp.h.10.mlp.c_proj.bias', 'temp.h.10.mlp.c_proj.weight', 'temp.h.11.attn.c_attn.bias', 'temp.h.11.attn.c_attn.weight', 'temp.h.11.attn.c_proj.bias', 'temp.h.11.attn.c_proj.weight', 'temp.h.11.ln_1.bias', 'temp.h.11.ln_1.weight', 'temp.h.11.ln_2.bias', 'temp.h.11.ln_2.weight', 'temp.h.11.mlp.c_fc.bias', 'temp.h.11.mlp.c_fc.weight', 'temp.h.11.mlp.c_proj.bias', 'temp.h.11.mlp.c_proj.weight', 'temp.h.2.attn.c_attn.bias', 'temp.h.2.attn.c_attn.weight', 'temp.h.2.attn.c_proj.bias', 'temp.h.2.attn.c_proj.weight', 'temp.h.2.ln_1.bias', 'temp.h.2.ln_1.weight', 'temp.h.2.ln_2.bias', 'temp.h.2.ln_2.weight', 'temp.h.2.mlp.c_fc.bias', 'temp.h.2.mlp.c_fc.weight', 'temp.h.2.mlp.c_proj.bias', 'temp.h.2.mlp.c_proj.weight', 'temp.h.3.attn.c_attn.bias', 'temp.h.3.attn.c_attn.weight', 'temp.h.3.attn.c_proj.bias', 'temp.h.3.attn.c_proj.weight', 'temp.h.3.ln_1.bias', 'temp.h.3.ln_1.weight', 'temp.h.3.ln_2.bias', 'temp.h.3.ln_2.weight', 'temp.h.3.mlp.c_fc.bias', 'temp.h.3.mlp.c_fc.weight', 'temp.h.3.mlp.c_proj.bias', 'temp.h.3.mlp.c_proj.weight', 'temp.h.4.attn.c_attn.bias', 'temp.h.4.attn.c_attn.weight', 'temp.h.4.attn.c_proj.bias', 'temp.h.4.attn.c_proj.weight', 'temp.h.4.ln_1.bias', 'temp.h.4.ln_1.weight', 'temp.h.4.ln_2.bias', 'temp.h.4.ln_2.weight', 'temp.h.4.mlp.c_fc.bias', 'temp.h.4.mlp.c_fc.weight', 'temp.h.4.mlp.c_proj.bias', 'temp.h.4.mlp.c_proj.weight', 'temp.h.5.attn.c_attn.bias', 'temp.h.5.attn.c_attn.weight', 'temp.h.5.attn.c_proj.bias', 'temp.h.5.attn.c_proj.weight', 'temp.h.5.ln_1.bias', 'temp.h.5.ln_1.weight', 'temp.h.5.ln_2.bias', 'temp.h.5.ln_2.weight', 'temp.h.5.mlp.c_fc.bias', 'temp.h.5.mlp.c_fc.weight', 'temp.h.5.mlp.c_proj.bias', 'temp.h.5.mlp.c_proj.weight', 'temp.h.6.attn.c_attn.bias', 'temp.h.6.attn.c_attn.weight', 'temp.h.6.attn.c_proj.bias', 'temp.h.6.attn.c_proj.weight', 'temp.h.6.ln_1.bias', 'temp.h.6.ln_1.weight', 'temp.h.6.ln_2.bias', 'temp.h.6.ln_2.weight', 'temp.h.6.mlp.c_fc.bias', 'temp.h.6.mlp.c_fc.weight', 'temp.h.6.mlp.c_proj.bias', 'temp.h.6.mlp.c_proj.weight', 'temp.h.7.attn.c_attn.bias', 'temp.h.7.attn.c_attn.weight', 'temp.h.7.attn.c_proj.bias', 'temp.h.7.attn.c_proj.weight', 'temp.h.7.ln_1.bias', 'temp.h.7.ln_1.weight', 'temp.h.7.ln_2.bias', 'temp.h.7.ln_2.weight', 'temp.h.7.mlp.c_fc.bias', 'temp.h.7.mlp.c_fc.weight', 'temp.h.7.mlp.c_proj.bias', 'temp.h.7.mlp.c_proj.weight', 'temp.h.8.attn.c_attn.bias', 'temp.h.8.attn.c_attn.weight', 'temp.h.8.attn.c_proj.bias', 'temp.h.8.attn.c_proj.weight', 'temp.h.8.ln_1.bias', 'temp.h.8.ln_1.weight', 'temp.h.8.ln_2.bias', 'temp.h.8.ln_2.weight', 'temp.h.8.mlp.c_fc.bias', 'temp.h.8.mlp.c_fc.weight', 'temp.h.8.mlp.c_proj.bias', 'temp.h.8.mlp.c_proj.weight', 'temp.h.9.attn.c_attn.bias', 'temp.h.9.attn.c_attn.weight', 'temp.h.9.attn.c_proj.bias', 'temp.h.9.attn.c_proj.weight', 'temp.h.9.ln_1.bias', 'temp.h.9.ln_1.weight', 'temp.h.9.ln_2.bias', 'temp.h.9.ln_2.weight', 'temp.h.9.mlp.c_fc.bias', 'temp.h.9.mlp.c_fc.weight', 'temp.h.9.mlp.c_proj.bias', 'temp.h.9.mlp.c_proj.weight', 'temp.ln_f.bias', 'temp.ln_f.weight', 'temp.wpe.weight', 'temp.wte.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "original final state: tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         [ 0.3843, -0.0618, -0.9933,  ...,  0.2799,  0.7343, -0.2728],\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511]]])\n",
      "before shape: torch.Size([1, 5, 50257])\n",
      "before: tensor([[[ -33.8917,  -33.5870,  -36.9429,  ...,  -41.3181,  -40.5135,\n",
      "           -34.1144],\n",
      "         [-127.1116, -127.4170, -132.3704,  ..., -134.7474, -132.0798,\n",
      "          -128.8874],\n",
      "         [ -62.7075,  -63.1996,  -66.4456,  ...,  -74.8977,  -70.6860,\n",
      "           -66.3801],\n",
      "         [ -80.0835,  -80.9817,  -85.6755,  ...,  -92.5178,  -91.1599,\n",
      "           -84.1941],\n",
      "         [-132.9957, -133.6038, -134.3203,  ..., -143.4922, -143.1438,\n",
      "          -128.2048]]])\n",
      "Layer 6 original activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 6 modified activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 7 pre-view activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 original activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 modified activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 8 pre-view activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 original activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 modified activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 9 pre-view activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 original activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 modified activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 10 pre-view activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 original activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 modified activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 11 pre-view activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 original activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 modified activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 12 pre-view activation: tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state original after ln_f:  tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         [ 0.3843, -0.0618, -0.9933,  ...,  0.2799,  0.7343, -0.2728],\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511]]])\n",
      "final state modified before ln_f:  tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state modified after ln_f:  tensor([[[-0.0204,  0.0510, -0.1376,  ..., -0.1995, -0.0132, -0.0067],\n",
      "         [-0.0417,  0.1180, -0.1390,  ..., -0.1141, -0.2644,  0.1862],\n",
      "         [ 0.2782, -0.8400,  0.0805,  ...,  0.0804, -0.1518, -0.1054],\n",
      "         [ 0.2743, -0.0715, -0.4907,  ...,  0.2628,  0.6921, -0.2545],\n",
      "         [ 0.2465, -0.2192, -0.1106,  ..., -0.0872,  0.1547,  0.0138]]])\n",
      "input_shape: tensor([[ 8491,   345, 18951, 13658,    30,   262]])\n",
      "original final state: tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         [ 0.3843, -0.0618, -0.9933,  ...,  0.2799,  0.7343, -0.2728],\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511],\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480]]])\n",
      "before shape: torch.Size([1, 6, 50257])\n",
      "before: tensor([[[ -33.8917,  -33.5870,  -36.9429,  ...,  -41.3181,  -40.5135,\n",
      "           -34.1144],\n",
      "         [-127.1116, -127.4170, -132.3704,  ..., -134.7474, -132.0798,\n",
      "          -128.8874],\n",
      "         [ -62.7075,  -63.1996,  -66.4456,  ...,  -74.8977,  -70.6860,\n",
      "           -66.3801],\n",
      "         [ -80.0835,  -80.9817,  -85.6755,  ...,  -92.5178,  -91.1599,\n",
      "           -84.1941],\n",
      "         [-132.9957, -133.6038, -134.3203,  ..., -143.4922, -143.1438,\n",
      "          -128.2048],\n",
      "         [ -78.5450,  -77.5647,  -78.6244,  ...,  -81.2012,  -81.3607,\n",
      "           -77.0585]]])\n",
      "Layer 6 original activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102],\n",
      "         [-1.4301,  0.8493, -0.7682,  ...,  0.1268, -0.6181, -1.4423]]])\n",
      "Layer 6 modified activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 7 pre-view activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 original activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988],\n",
      "         [-1.3786,  1.8180, -0.5061,  ...,  0.1050,  0.3281, -0.7190]]])\n",
      "Layer 7 modified activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 8 pre-view activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 original activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997],\n",
      "         [-1.3448,  0.9685, -1.0986,  ...,  1.7241,  2.1071, -3.5242]]])\n",
      "Layer 8 modified activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 9 pre-view activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 original activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154],\n",
      "         [-1.1634,  0.5579, -1.2118,  ...,  2.2955,  5.0856, -4.8884]]])\n",
      "Layer 9 modified activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 10 pre-view activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 original activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528],\n",
      "         [-1.3639, -0.4808, -0.8758,  ...,  2.7300,  8.8225, -5.1532]]])\n",
      "Layer 10 modified activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 11 pre-view activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 original activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557],\n",
      "         [-0.2250, -0.3171, -0.8238,  ...,  3.5399,  9.2573, -5.6612]]])\n",
      "Layer 11 modified activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 12 pre-view activation: tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state original after ln_f:  tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         [ 0.3843, -0.0618, -0.9933,  ...,  0.2799,  0.7343, -0.2728],\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511],\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480]]])\n",
      "final state modified before ln_f:  tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state modified after ln_f:  tensor([[[-0.0204,  0.0510, -0.1376,  ..., -0.1995, -0.0132, -0.0067],\n",
      "         [-0.0417,  0.1180, -0.1390,  ..., -0.1141, -0.2644,  0.1862],\n",
      "         [ 0.2782, -0.8400,  0.0805,  ...,  0.0804, -0.1518, -0.1054],\n",
      "         [ 0.2743, -0.0715, -0.4907,  ...,  0.2628,  0.6921, -0.2545],\n",
      "         [ 0.2465, -0.2192, -0.1106,  ..., -0.0872,  0.1547,  0.0138]]])\n",
      "input_shape: tensor([[ 8491,   345, 18951, 13658,    30,   262,   262]])\n",
      "original final state: tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511],\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480],\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928]]])\n",
      "before shape: torch.Size([1, 7, 50257])\n",
      "before: tensor([[[ -33.8917,  -33.5870,  -36.9429,  ...,  -41.3181,  -40.5135,\n",
      "           -34.1144],\n",
      "         [-127.1116, -127.4170, -132.3704,  ..., -134.7474, -132.0798,\n",
      "          -128.8874],\n",
      "         [ -62.7075,  -63.1996,  -66.4456,  ...,  -74.8977,  -70.6860,\n",
      "           -66.3801],\n",
      "         ...,\n",
      "         [-132.9957, -133.6038, -134.3203,  ..., -143.4922, -143.1438,\n",
      "          -128.2048],\n",
      "         [ -78.5450,  -77.5647,  -78.6244,  ...,  -81.2012,  -81.3607,\n",
      "           -77.0585],\n",
      "         [ -79.7551,  -78.7093,  -79.8869,  ...,  -82.0833,  -82.3333,\n",
      "           -78.0586]]])\n",
      "Layer 6 original activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         ...,\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102],\n",
      "         [-1.4301,  0.8493, -0.7682,  ...,  0.1268, -0.6181, -1.4423],\n",
      "         [-1.2137,  0.8809, -0.5447,  ..., -0.1196, -0.7481, -1.7479]]])\n",
      "Layer 6 modified activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 7 pre-view activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 original activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         ...,\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988],\n",
      "         [-1.3786,  1.8180, -0.5061,  ...,  0.1050,  0.3281, -0.7190],\n",
      "         [-1.1402,  1.7075, -0.2559,  ..., -0.5199,  0.1263, -0.9121]]])\n",
      "Layer 7 modified activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 8 pre-view activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 original activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         ...,\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997],\n",
      "         [-1.3448,  0.9685, -1.0986,  ...,  1.7241,  2.1071, -3.5242],\n",
      "         [-1.0963,  0.6870, -0.9673,  ...,  1.1460,  1.9741, -3.5756]]])\n",
      "Layer 8 modified activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 9 pre-view activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 original activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         ...,\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154],\n",
      "         [-1.1634,  0.5579, -1.2118,  ...,  2.2955,  5.0856, -4.8884],\n",
      "         [-1.1032,  0.5126, -0.8304,  ...,  1.6120,  4.8289, -4.8856]]])\n",
      "Layer 9 modified activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 10 pre-view activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 original activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         ...,\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528],\n",
      "         [-1.3639, -0.4808, -0.8758,  ...,  2.7300,  8.8225, -5.1532],\n",
      "         [-1.2952, -0.4678, -0.5090,  ...,  1.5976,  8.7051, -4.8967]]])\n",
      "Layer 10 modified activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 11 pre-view activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 original activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         ...,\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557],\n",
      "         [-0.2250, -0.3171, -0.8238,  ...,  3.5399,  9.2573, -5.6612],\n",
      "         [-0.3454, -0.5414, -0.6895,  ...,  2.7585,  9.5583, -5.0797]]])\n",
      "Layer 11 modified activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 12 pre-view activation: tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state original after ln_f:  tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [ 0.3454, -0.2649, -0.2760,  ..., -0.1063,  0.1444,  0.0511],\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480],\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928]]])\n",
      "final state modified before ln_f:  tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state modified after ln_f:  tensor([[[-0.0204,  0.0510, -0.1376,  ..., -0.1995, -0.0132, -0.0067],\n",
      "         [-0.0417,  0.1180, -0.1390,  ..., -0.1141, -0.2644,  0.1862],\n",
      "         [ 0.2782, -0.8400,  0.0805,  ...,  0.0804, -0.1518, -0.1054],\n",
      "         [ 0.2743, -0.0715, -0.4907,  ...,  0.2628,  0.6921, -0.2545],\n",
      "         [ 0.2465, -0.2192, -0.1106,  ..., -0.0872,  0.1547,  0.0138]]])\n",
      "input_shape: tensor([[ 8491,   345, 18951, 13658,    30,   262,   262,   262]])\n",
      "original final state: tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480],\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928],\n",
      "         [-0.3696, -0.0338, -0.3013,  ...,  0.0233,  0.5261,  0.0078]]])\n",
      "before shape: torch.Size([1, 8, 50257])\n",
      "before: tensor([[[ -33.8917,  -33.5870,  -36.9430,  ...,  -41.3181,  -40.5135,\n",
      "           -34.1144],\n",
      "         [-127.1116, -127.4170, -132.3703,  ..., -134.7474, -132.0798,\n",
      "          -128.8874],\n",
      "         [ -62.7075,  -63.1996,  -66.4456,  ...,  -74.8977,  -70.6860,\n",
      "           -66.3801],\n",
      "         ...,\n",
      "         [ -78.5450,  -77.5647,  -78.6244,  ...,  -81.2011,  -81.3607,\n",
      "           -77.0585],\n",
      "         [ -79.7551,  -78.7093,  -79.8869,  ...,  -82.0833,  -82.3332,\n",
      "           -78.0586],\n",
      "         [ -73.9618,  -74.5008,  -76.2526,  ...,  -79.6424,  -78.2773,\n",
      "           -72.9292]]])\n",
      "Layer 6 original activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0261,  0.6047, -0.9181],\n",
      "         ...,\n",
      "         [-1.4301,  0.8493, -0.7682,  ...,  0.1268, -0.6181, -1.4423],\n",
      "         [-1.2137,  0.8809, -0.5447,  ..., -0.1196, -0.7481, -1.7479],\n",
      "         [-1.7971,  0.9363,  0.8992,  ..., -1.1298, -1.1878, -1.6476]]])\n",
      "Layer 6 modified activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 7 pre-view activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 original activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         ...,\n",
      "         [-1.3786,  1.8180, -0.5061,  ...,  0.1050,  0.3281, -0.7190],\n",
      "         [-1.1402,  1.7075, -0.2559,  ..., -0.5199,  0.1263, -0.9121],\n",
      "         [-2.5078,  1.3250,  0.8237,  ..., -1.5617, -1.0857, -0.7535]]])\n",
      "Layer 7 modified activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 8 pre-view activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 original activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         ...,\n",
      "         [-1.3448,  0.9685, -1.0986,  ...,  1.7241,  2.1071, -3.5243],\n",
      "         [-1.0963,  0.6870, -0.9673,  ...,  1.1460,  1.9741, -3.5756],\n",
      "         [-1.9013, -0.0872,  0.3074,  ...,  0.0517,  0.6579, -1.8511]]])\n",
      "Layer 8 modified activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 9 pre-view activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 original activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         ...,\n",
      "         [-1.1634,  0.5579, -1.2118,  ...,  2.2955,  5.0856, -4.8884],\n",
      "         [-1.1032,  0.5126, -0.8304,  ...,  1.6120,  4.8289, -4.8856],\n",
      "         [-3.5788,  0.0440,  0.3729,  ...,  0.5688,  0.8609, -3.2756]]])\n",
      "Layer 9 modified activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 10 pre-view activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 original activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         ...,\n",
      "         [-1.3639, -0.4808, -0.8758,  ...,  2.7300,  8.8225, -5.1532],\n",
      "         [-1.2952, -0.4678, -0.5090,  ...,  1.5976,  8.7051, -4.8967],\n",
      "         [-4.1732,  0.5649,  0.4212,  ...,  0.5921,  4.2756, -2.2398]]])\n",
      "Layer 10 modified activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 11 pre-view activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 original activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7371],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         ...,\n",
      "         [-0.2250, -0.3171, -0.8238,  ...,  3.5399,  9.2573, -5.6612],\n",
      "         [-0.3454, -0.5414, -0.6895,  ...,  2.7585,  9.5583, -5.0798],\n",
      "         [-5.0288, -0.9961, -0.9387,  ...,  1.6814,  7.5484, -1.3157]]])\n",
      "Layer 11 modified activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 12 pre-view activation: tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state original after ln_f:  tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [-0.0251, -0.1005, -0.3058,  ...,  0.1435,  0.7062, -0.3480],\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928],\n",
      "         [-0.3696, -0.0338, -0.3013,  ...,  0.0233,  0.5261,  0.0078]]])\n",
      "final state modified before ln_f:  tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state modified after ln_f:  tensor([[[-0.0204,  0.0510, -0.1376,  ..., -0.1995, -0.0132, -0.0067],\n",
      "         [-0.0417,  0.1180, -0.1390,  ..., -0.1141, -0.2644,  0.1862],\n",
      "         [ 0.2782, -0.8400,  0.0805,  ...,  0.0804, -0.1518, -0.1054],\n",
      "         [ 0.2743, -0.0715, -0.4907,  ...,  0.2628,  0.6921, -0.2545],\n",
      "         [ 0.2465, -0.2192, -0.1106,  ..., -0.0872,  0.1547,  0.0138]]])\n",
      "input_shape: tensor([[ 8491,   345, 18951, 13658,    30,   262,   262,   262,   262]])\n",
      "original final state: tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928],\n",
      "         [-0.3696, -0.0338, -0.3013,  ...,  0.0233,  0.5261,  0.0078],\n",
      "         [-0.3805, -0.0070, -0.4318,  ...,  0.0702,  0.4039,  0.0692]]])\n",
      "before shape: torch.Size([1, 9, 50257])\n",
      "before: tensor([[[ -33.8917,  -33.5870,  -36.9430,  ...,  -41.3181,  -40.5135,\n",
      "           -34.1144],\n",
      "         [-127.1116, -127.4170, -132.3703,  ..., -134.7474, -132.0798,\n",
      "          -128.8874],\n",
      "         [ -62.7075,  -63.1996,  -66.4456,  ...,  -74.8977,  -70.6860,\n",
      "           -66.3801],\n",
      "         ...,\n",
      "         [ -79.7551,  -78.7093,  -79.8869,  ...,  -82.0833,  -82.3332,\n",
      "           -78.0586],\n",
      "         [ -73.9618,  -74.5008,  -76.2526,  ...,  -79.6424,  -78.2773,\n",
      "           -72.9292],\n",
      "         [ -76.0943,  -76.9535,  -79.2925,  ...,  -82.8238,  -80.9221,\n",
      "           -74.8904]]])\n",
      "Layer 6 original activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0261,  0.6047, -0.9181],\n",
      "         ...,\n",
      "         [-1.2137,  0.8809, -0.5447,  ..., -0.1196, -0.7481, -1.7479],\n",
      "         [-1.7971,  0.9363,  0.8992,  ..., -1.1298, -1.1878, -1.6476],\n",
      "         [-2.3430,  1.2728,  1.2125,  ..., -1.0821, -1.5875, -1.7024]]])\n",
      "Layer 6 modified activation: tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "Layer 7 pre-view activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 7 original activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         ...,\n",
      "         [-1.1402,  1.7075, -0.2559,  ..., -0.5199,  0.1263, -0.9121],\n",
      "         [-2.5078,  1.3250,  0.8237,  ..., -1.5617, -1.0857, -0.7535],\n",
      "         [-2.6933,  1.8601,  0.8795,  ..., -1.2462, -1.7996, -1.1362]]])\n",
      "Layer 7 modified activation: tensor([[[ 0.8602,  0.1959,  0.4753,  ..., -1.8215, -0.2200,  0.4110],\n",
      "         [-0.5927,  0.9537, -2.2768,  ..., -1.5256, -2.6308,  1.6227],\n",
      "         [ 3.2329, -4.1209, -2.8176,  ..., -3.9215,  1.4423, -1.0927],\n",
      "         [ 4.3366,  0.8113, -2.9855,  ..., -1.3056,  5.1563,  0.3707],\n",
      "         [ 1.3002,  1.2545, -1.8011,  ..., -3.2269, -0.4410,  2.9988]]])\n",
      "Layer 8 pre-view activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 8 original activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         ...,\n",
      "         [-1.0963,  0.6870, -0.9673,  ...,  1.1460,  1.9741, -3.5756],\n",
      "         [-1.9013, -0.0872,  0.3074,  ...,  0.0517,  0.6579, -1.8511],\n",
      "         [-1.5914,  0.0798,  0.4558,  ...,  0.6259, -0.5095, -1.4599]]])\n",
      "Layer 8 modified activation: tensor([[[ 0.8107,  0.3557,  0.3657,  ..., -1.7753, -0.2571,  0.2915],\n",
      "         [-0.4436,  1.6893, -3.0503,  ..., -1.3557, -1.7579,  1.4882],\n",
      "         [ 4.4635, -4.2780, -2.9567,  ..., -3.3165,  2.0502,  0.1191],\n",
      "         [ 4.3690,  0.8833, -3.5049,  ..., -2.0694,  6.3308,  0.1000],\n",
      "         [ 2.0955,  1.4579, -2.0989,  ..., -3.1561, -0.1891,  1.5997]]])\n",
      "Layer 9 pre-view activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 9 original activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         ...,\n",
      "         [-1.1032,  0.5126, -0.8304,  ...,  1.6120,  4.8289, -4.8856],\n",
      "         [-3.5788,  0.0440,  0.3729,  ...,  0.5688,  0.8609, -3.2756],\n",
      "         [-3.7567,  0.2525,  0.1636,  ...,  0.8021, -0.2996, -2.7978]]])\n",
      "Layer 9 modified activation: tensor([[[ 0.8349,  0.4499,  0.3391,  ..., -1.6474, -0.2289,  0.1704],\n",
      "         [-2.1683,  1.1895, -2.8410,  ..., -1.6105, -1.7115,  1.7752],\n",
      "         [ 3.5599, -4.8261, -3.9233,  ..., -2.9283,  2.0972, -0.7958],\n",
      "         [ 3.0374,  0.7363, -4.3528,  ..., -1.4986,  5.2518, -0.4584],\n",
      "         [ 0.0946,  0.6516, -1.4725,  ..., -3.6932, -0.9207, -0.2154]]])\n",
      "Layer 10 pre-view activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 10 original activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         ...,\n",
      "         [-1.2952, -0.4678, -0.5090,  ...,  1.5976,  8.7051, -4.8967],\n",
      "         [-4.1732,  0.5649,  0.4212,  ...,  0.5921,  4.2756, -2.2398],\n",
      "         [-4.8724,  1.0944, -0.3529,  ...,  0.9734,  2.7571, -1.5048]]])\n",
      "Layer 10 modified activation: tensor([[[ 0.7052,  0.6680,  0.1108,  ..., -1.5906, -0.1200, -0.0543],\n",
      "         [-3.2633,  1.2577, -3.1362,  ..., -0.5989, -1.1784,  0.8725],\n",
      "         [ 3.9552, -4.8081, -3.0604,  ..., -3.0959,  1.1724, -0.2506],\n",
      "         [ 2.9354,  1.0051, -3.7500,  ...,  0.1015,  6.5043, -1.2252],\n",
      "         [ 3.2939, -1.5921, -1.9707,  ..., -3.8947,  1.0922, -1.0528]]])\n",
      "Layer 11 pre-view activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 11 original activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7371],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         ...,\n",
      "         [-0.3454, -0.5414, -0.6895,  ...,  2.7585,  9.5583, -5.0798],\n",
      "         [-5.0288, -0.9961, -0.9387,  ...,  1.6814,  7.5484, -1.3157],\n",
      "         [-6.0541, -0.6171, -2.5848,  ...,  1.7145,  6.2630, -0.3707]]])\n",
      "Layer 11 modified activation: tensor([[[ 0.6099,  0.9741, -0.2918,  ..., -1.6327,  0.1319, -0.1614],\n",
      "         [-2.2681,  2.1261, -2.1669,  ..., -1.7211, -2.2743,  0.7372],\n",
      "         [ 3.7503, -4.4424, -1.8829,  ..., -3.1761, -0.2587, -1.3854],\n",
      "         [ 3.8170,  0.3074, -5.7211,  ...,  1.2217, 11.1611, -1.7860],\n",
      "         [ 4.3441, -1.7713, -0.6334,  ..., -1.3849,  2.2614,  0.6557]]])\n",
      "Layer 12 pre-view activation: tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state original after ln_f:  tensor([[[-0.0275,  0.1067, -0.3269,  ..., -0.2302, -0.0401,  0.0264],\n",
      "         [-0.0572,  0.1988, -0.3297,  ..., -0.1360, -0.3159,  0.2592],\n",
      "         [ 0.3898, -1.1184,  0.0847,  ...,  0.0786, -0.1922, -0.0928],\n",
      "         ...,\n",
      "         [-0.0475, -0.1348, -0.3164,  ...,  0.1016,  0.7271, -0.2928],\n",
      "         [-0.3696, -0.0338, -0.3013,  ...,  0.0233,  0.5261,  0.0078],\n",
      "         [-0.3805, -0.0070, -0.4318,  ...,  0.0702,  0.4039,  0.0692]]])\n",
      "final state modified before ln_f:  tensor([[[ 0.2411,  1.1978, -1.3271,  ..., -2.1556,  0.3375,  0.4252],\n",
      "         [-0.5997,  1.7759, -2.0478,  ..., -1.6774, -3.9131,  2.7900],\n",
      "         [ 2.7619, -8.3248,  0.8018,  ...,  0.8007, -1.5015, -1.0417],\n",
      "         [ 3.9957, -1.2877, -7.6911,  ...,  3.8193, 10.3766, -4.0828],\n",
      "         [ 4.4882, -3.9955, -2.0169,  ..., -1.5897,  2.8170,  0.2495]]])\n",
      "final state modified after ln_f:  tensor([[[-0.0204,  0.0510, -0.1376,  ..., -0.1995, -0.0132, -0.0067],\n",
      "         [-0.0417,  0.1180, -0.1390,  ..., -0.1141, -0.2644,  0.1862],\n",
      "         [ 0.2782, -0.8400,  0.0805,  ...,  0.0804, -0.1518, -0.1054],\n",
      "         [ 0.2743, -0.0715, -0.4907,  ...,  0.2628,  0.6921, -0.2545],\n",
      "         [ 0.2465, -0.2192, -0.1106,  ..., -0.0872,  0.1547,  0.0138]]])\n",
      "Are you introverted? the the the the the\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "set_seed(123)\n",
    "custom_model = ModifiedGPT2Model(model.config)\n",
    "custom_model.load_state_dict(model.state_dict())  # 复制权重\n",
    "\"\"\"\n",
    "set_seed(123)\n",
    "custom_model = ModifiedGPT2Model.from_pretrained('gpt2', output_hidden_states=True)\n",
    "custom_model.set_modified_output(modified_activations)\n",
    "inputs = auto_tokenizer.encode(\"Are you introverted?\", return_tensors=\"pt\")\n",
    "generated_text_ids = custom_model.generate(inputs, max_length=10, pad_token_id=auto_tokenizer.eos_token_id)\n",
    "generated_text = auto_tokenizer.decode(generated_text_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Are you introverted?\"\n",
    "tokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str)\n",
    "print(len(activation_cache))\n",
    "activation = get_activation_hf(activation_cache, layer_index)\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\n",
    "print(activation)\n",
    "modified_recon_activations_new = activation\n",
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(error_after)\n",
    "print(mse_error_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44f18912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import CausalLMOutputWithPast, CausalLMOutputWithCrossAttentions\n",
    "class ModifiedGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config, layer_to_modify=6, feature_indices = [53912], feature_values = [10]):\n",
    "        super().__init__(config)\n",
    "        self.modified_output = None  # 用于存储第六层的原始输出\n",
    "        self.ln_f = GPT2Model(config=config).from_pretrained('gpt2').ln_f\n",
    "        self.transformer = GPT2Model(config=config).from_pretrained('gpt2')\n",
    "        self.lm_head = GPT2LMHeadModel(config=config).from_pretrained('gpt2').lm_head\n",
    "        self.feature_indices = feature_indices\n",
    "        self.feature_values = feature_values\n",
    "        self.layer_to_modify = layer_to_modify\n",
    "\n",
    "    \n",
    "    def set_modified_output(self, hidden_list):\n",
    "        activation = hidden_list[self.layer_to_modify][0]\n",
    "        # print(\"activation shape\", activation.shape)\n",
    "        latent_activations, recon_activations = encode_decode(autoencoder, activation)\n",
    "        mse_error, error = calculate_error(activation, recon_activations)\n",
    "        modified_recon_activations = feature_steering(autoencoder, activation, self.feature_indices, self.feature_values)\n",
    "        modified_recon_activations_new = modified_recon_activations + error\n",
    "        self.modified_output = modified_recon_activations_new.unsqueeze(0)\n",
    "        # print(self.modified_output.shape)\n",
    "    \n",
    "    \n",
    "    def set_modified_output_1(self, hidden_list):\n",
    "        activation = hidden_list[self.layer_to_modify][0]\n",
    "        #print(\"activation shape\", activation.shape)\n",
    "        modified_recon_activations_new = activation\n",
    "        self.modified_output = modified_recon_activations_new.unsqueeze(0)\n",
    "        #print(\"modified activation shape\", self.modified_output.shape)\n",
    "\n",
    "    def forward(self, input_ids=None, labels=None, use_cache=False, output_hidden_states=True, return_dict=None, **kwargs):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        # print(\"input_id\", input_ids)\n",
    "        tf_output = self.transformer(input_ids=input_ids, use_cache=False, output_hidden_states=output_hidden_states, return_dict=return_dict, **kwargs)\n",
    "        # print(len(tf_output))\n",
    "        final_hidden_states = tf_output[0]\n",
    "        logits_before = self.lm_head(final_hidden_states)\n",
    "        # print(\"logits before:\", logits_before)\n",
    "        hidden_states_list = tf_output[1]\n",
    "\n",
    "        self.set_modified_output(hidden_states_list)\n",
    "        # 继续通过剩余的层\n",
    "        if self.modified_output is not None:\n",
    "            # 从指定层开始使用提供的激活值进行修改\n",
    "            modified_states = self.modified_output\n",
    "            for i in range(self.layer_to_modify, len(self.transformer.h)):\n",
    "                layer_module = self.transformer.h[i]\n",
    "                layer_outputs = layer_module(modified_states)  \n",
    "                modified_states = layer_outputs[0]\n",
    "            # 将最终输出设置为最后一层修改后的输出\n",
    "            final_hidden_states = modified_states\n",
    "            final_hidden_states = self.ln_f(final_hidden_states)\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.transformer.first_device)\n",
    "            final_hidden_states = final_hidden_states.to(self.lm_head.weight.device)\n",
    "        # 输出最后一层的hidden state给LM头\n",
    "        #print(\"hiddent state before\", tf_output[0])\n",
    "        #print(\"hiddent state after\", final_hidden_states)\n",
    "        lm_logits = self.lm_head(final_hidden_states)\n",
    "        # print(\"logits after:\", lm_logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + tf_output[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithCrossAttentions(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=tf_output.past_key_values,\n",
    "            hidden_states=final_hidden_states,\n",
    "            attentions=tf_output.attentions,\n",
    "            cross_attentions=tf_output.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "03a171a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 2.9290])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 14.6451])\n",
      "Feature 53912 modified with +5\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.6225, 0.6823, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.8459, 0.0000, 5.0568, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 4.5709, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.9216,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.3516, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 2.9290, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 21.4770, 39.9168,  0.0000,  3.1124,  3.4116,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.2296,  0.0000, 25.2840,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.8545,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 19.6082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, 16.7582,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 14.6451,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +5\n",
      "Are you introverted?\n",
      "\n",
      "I'm not. I'm not a big fan of the word \"introverted\" or \"introverted\" or \"introverted\" or \"introverted\" or \"introverted\" or\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_seed(123)\n",
    "feature_indices = [53912] \n",
    "feature_values = [5]\n",
    "custom_model = ModifiedGPT2Model.from_pretrained('gpt2', output_hidden_states=True, layer_to_modify=6, feature_indices = feature_indices, feature_values = feature_values)\n",
    "inputs = auto_tokenizer.encode(\"Are you introverted?\", return_tensors=\"pt\")\n",
    "\n",
    "generated_text_ids = custom_model.generate(inputs, max_length=50, pad_token_id=auto_tokenizer.eos_token_id)\n",
    "generated_text = auto_tokenizer.decode(generated_text_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dda4a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "input_id tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "Step 1:\n",
      "  Candidate 1:  the (Logit: -29.919227600097656)\n",
      "  Candidate 2:  a (Logit: -30.527088165283203)\n",
      "  Candidate 3:  to (Logit: -30.872114181518555)\n",
      "  Candidate 4: , (Logit: -31.005409240722656)\n",
      "  Candidate 5: \n",
      " (Logit: -31.133554458618164)\n",
      "  Candidate 6:  you (Logit: -31.302366256713867)\n",
      "  Candidate 7: . (Logit: -31.325267791748047)\n",
      "  Candidate 8:  in (Logit: -31.41859245300293)\n",
      "  Candidate 9:  that (Logit: -31.46228790283203)\n",
      "  Candidate 10:  it (Logit: -31.574438095092773)\n",
      "\n",
      "\n",
      "Step 2:\n",
      "  Candidate 1:  a (Logit: -119.24162292480469)\n",
      "  Candidate 2:  sure (Logit: -119.3289794921875)\n",
      "  Candidate 3:  going (Logit: -119.415283203125)\n",
      "  Candidate 4:  ready (Logit: -119.50483703613281)\n",
      "  Candidate 5:  looking (Logit: -120.21624755859375)\n",
      "  Candidate 6:  still (Logit: -120.22654724121094)\n",
      "  Candidate 7:  interested (Logit: -120.45963287353516)\n",
      "  Candidate 8:  using (Logit: -120.4637680053711)\n",
      "  Candidate 9:  in (Logit: -120.65441131591797)\n",
      "  Candidate 10:  worried (Logit: -120.6690444946289)\n",
      "\n",
      "\n",
      "Step 3:\n",
      "  Candidate 1: verted (Logit: -35.5081787109375)\n",
      "  Candidate 2: ism (Logit: -36.81892013549805)\n",
      "  Candidate 3: icism (Logit: -36.85387420654297)\n",
      "  Candidate 4: ude (Logit: -37.110755920410156)\n",
      "  Candidate 5: version (Logit: -37.97685623168945)\n",
      "  Candidate 6: ics (Logit: -38.02839279174805)\n",
      "  Candidate 7: / (Logit: -38.153831481933594)\n",
      "  Candidate 8: ibility (Logit: -39.44965744018555)\n",
      "  Candidate 9: ¨ (Logit: -39.462608337402344)\n",
      "  Candidate 10: ceptive (Logit: -39.577239990234375)\n",
      "\n",
      "\n",
      "Step 4:\n",
      "  Candidate 1: icism (Logit: -19.675743103027344)\n",
      "  Candidate 2: verted (Logit: -20.037918090820312)\n",
      "  Candidate 3: ude (Logit: -20.619001388549805)\n",
      "  Candidate 4: ism (Logit: -20.752243041992188)\n",
      "  Candidate 5: ics (Logit: -22.037841796875)\n",
      "  Candidate 6: ceptive (Logit: -22.085765838623047)\n",
      "  Candidate 7: version (Logit: -23.08926010131836)\n",
      "  Candidate 8: ibility (Logit: -23.39684295654297)\n",
      "  Candidate 9: ¨ (Logit: -23.813247680664062)\n",
      "  Candidate 10: akra (Logit: -24.26616668701172)\n",
      "\n",
      "\n",
      "Step 5:\n",
      "  Candidate 1: \n",
      " (Logit: -114.36338806152344)\n",
      "  Candidate 2:  I (Logit: -114.61329650878906)\n",
      "  Candidate 3:  You (Logit: -115.54961395263672)\n",
      "  Candidate 4:  It (Logit: -115.95182800292969)\n",
      "  Candidate 5:  Maybe (Logit: -116.10997772216797)\n",
      "  Candidate 6:  Well (Logit: -116.14437866210938)\n",
      "  Candidate 7:  If (Logit: -116.38446044921875)\n",
      "  Candidate 8:  What (Logit: -116.4944839477539)\n",
      "  Candidate 9:  Do (Logit: -116.5334701538086)\n",
      "  Candidate 10:  Or (Logit: -116.56732940673828)\n",
      "\n",
      "\n",
      "logits type Steered Output:  the avertedicism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_text_l, logits = chat_with_gpt2_logits(custom_model, inputs, auto_tokenizer)\n",
    "chat_with_gpt2_top_k_candidates(custom_model, inputs, auto_tokenizer)\n",
    "print(\"logits type Steered Output:\", generated_text_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
