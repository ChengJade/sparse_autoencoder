{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:02:50.010183Z",
     "start_time": "2024-07-22T20:02:43.397665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('D:\\ComputerScience\\Research\\PRADA\\sparse_autoencoder')\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# 导入库\n",
    "import torch\n",
    "import blobfile as bf\n",
    "from experiments.utils import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, AutoTokenizer, GPT2Tokenizer, GPT2Config, set_seed, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d299df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SAE from: az://openaipublic/sparse-autoencoder/gpt2-small/resid_post_mlp_v5_32k/autoencoders/6.pt\n",
      "State dictionary saved to ../model/gpt2_sae/sae_state_32k_layer_6.pt\n",
      "Downloading SAE from: az://openaipublic/sparse-autoencoder/gpt2-small/resid_post_mlp_v5_128k/autoencoders/6.pt\n"
     ]
    }
   ],
   "source": [
    "# 下载AutoEncoder\n",
    "position = \"resid_post_mlp\"\n",
    "layer_index = 6\n",
    "download_autoencoder(position, layer_index=layer_index, size=32)\n",
    "download_autoencoder(position, layer_index=layer_index, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f3b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_steering(autoencoder,x: torch.Tensor, feature_indices: list[int], feature_values: list[float]) -> torch.Tensor:\n",
    "    assert len(feature_indices) == len(feature_values), \"Feature indices and values must have the same length.\"\n",
    "    # feature_values = [max(min(value, 10), -10) for value in feature_values]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 获取原始特征表示和信息\n",
    "        latents, info = autoencoder.encode(x)\n",
    "        # 修改特征表示\n",
    "        for index, value in zip(feature_indices, feature_values):\n",
    "            print(\"original:\", latents[:, index])\n",
    "            if value > 0:\n",
    "                latents[:, index] *= value\n",
    "            else:\n",
    "                latents[:, index] = latents[:, index] / abs(value)\n",
    "            print(\"Modified:\", latents[:, index])\n",
    "            print(f\"Feature {index} modified with {'+' if value >= 0 else ''}{value}\")\n",
    "        # 使用修改后的特征表示通过解码器生成重构输出\n",
    "        modified_output = autoencoder.decode(latents, info)\n",
    "    return modified_output\n",
    "\n",
    "def calculate_error(input_tensor, reconstructed_activations) -> torch.Tensor:\n",
    "    # 计算误差\n",
    "    error = input_tensor - reconstructed_activations\n",
    "    # 可以选择使用不同的误差度量方式，这里使用均方误差（MSE）\n",
    "    normalized_mse = (reconstructed_activations - input_tensor).pow(2).sum(dim=1) / (input_tensor).pow(2).sum(dim=1)\n",
    "    return normalized_mse, error\n",
    "\n",
    "\n",
    "def compare_activations(tensor1, tensor2):\n",
    "    difference = tensor1 - tensor2\n",
    "    print(\"Difference between tensors:\\n\", difference)\n",
    "\n",
    "    # 计算差异的统计信息\n",
    "    mean_diff = torch.mean(difference)\n",
    "    std_diff = torch.std(difference)\n",
    "    print(f\"Mean difference: {mean_diff.item()}\")\n",
    "    print(f\"Standard deviation of difference: {std_diff.item()}\")\n",
    "\n",
    "    # 可视化差异\n",
    "    difference_np = difference.numpy()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.imshow(difference_np, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar(label='Difference')\n",
    "    plt.title('Difference between Reconstructed Activations and Modified Output')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Sample Index')\n",
    "    plt.show()\n",
    "\n",
    "def chat_with_gpt2_logits(model, tokens_id, tokenizer):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_id)\n",
    "        logits = outputs.logits\n",
    "        # 使用torch.argmax选出概率最高的token ids\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        # 解码生成的token ids\n",
    "        response = tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "    return response, logits\n",
    "\n",
    "def chat_with_gpt2_top_k_candidates(model, tokens_id, tokenizer, top_k=10):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_id)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # 选择每个时间步上概率最高的top_k个token的logits\n",
    "        top_k_logits, top_k_indices = torch.topk(logits, k=top_k, dim=-1)\n",
    "        \n",
    "        # 解码每个token的索引以获取token字符串\n",
    "        top_k_tokens = [\n",
    "            [tokenizer.decode([idx]) for idx in indices[0]] for indices in top_k_indices\n",
    "        ]\n",
    "\n",
    "    for step in range(min(10, logits.shape[1])):  # 限制打印至最多前10个token\n",
    "            print(f\"Step {step + 1}:\")\n",
    "            for i in range(top_k):\n",
    "                token = tokenizer.decode([top_k_indices[0, step, i]])\n",
    "                logit = top_k_logits[0, step, i].item()\n",
    "                print(f\"  Candidate {i + 1}: {token} (Logit: {logit})\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "    return top_k_tokens, top_k_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5bb1aac7ca685e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:03:05.660715Z",
     "start_time": "2024-07-22T20:02:50.012200Z"
    }
   },
   "outputs": [],
   "source": [
    "model, auto_tokenizer, device = load_model_hf(\"gpt2\")\n",
    "layer_index = 6\n",
    "autoencoder = load_autoencoder_from_local(layer_index, device, 128)\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ebf18",
   "metadata": {},
   "source": [
    "# Activation Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b49ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprompt = \"Are you introverted?\"\\nfeature_indices = [53912]\\nfeature_values = [10] \\ntokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\\nprint(\"Tokens ID (AutoTokenizer):\", tokens_id)\\nprint(\"Tokens String (AutoTokenizer):\", tokens_str)\\nprint(len(activation_cache))\\nactivation = get_activation_hf(activation_cache, layer_index)\\nprint(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\\nprint(activation)\\n\\nlatent_activations, recon_activations = encode_decode(autoencoder, activation)\\nmse_error, error = calculate_error(activation, recon_activations)\\n\\nmodified_recon_activations = feature_steering(autoencoder, activation, feature_indices, feature_values)\\nprint(\"orginal modified_recon_activations:\", modified_recon_activations)\\nprint(modified_recon_activations.shape)\\n\\nmodified_recon_activations_new = modified_recon_activations + error\\nprint(\"modified_recon_activations + error:\", modified_recon_activations_new)\\n\\nmse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\\nprint(error_after)\\nprint(mse_error_after)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "prompt = \"Are you introverted?\"\n",
    "feature_indices = [53912]\n",
    "feature_values = [10] \n",
    "tokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str)\n",
    "print(len(activation_cache))\n",
    "activation = get_activation_hf(activation_cache, layer_index)\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\n",
    "print(activation)\n",
    "\n",
    "latent_activations, recon_activations = encode_decode(autoencoder, activation)\n",
    "mse_error, error = calculate_error(activation, recon_activations)\n",
    "\n",
    "modified_recon_activations = feature_steering(autoencoder, activation, feature_indices, feature_values)\n",
    "print(\"orginal modified_recon_activations:\", modified_recon_activations)\n",
    "print(modified_recon_activations.shape)\n",
    "\n",
    "modified_recon_activations_new = modified_recon_activations + error\n",
    "print(\"modified_recon_activations + error:\", modified_recon_activations_new)\n",
    "\n",
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(error_after)\n",
    "print(mse_error_after)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e45a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens ID (AutoTokenizer): tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "Tokens String (AutoTokenizer): ['Are', 'Ġyou', 'Ġintro', 'verted', '?']\n",
      "13\n",
      "resid_post_mlp for layer 6: torch.Size([5, 768])\n",
      "tensor([[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "        [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "        [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "        [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "        [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 提取原始第六层\n",
    "prompt = \"Are you introverted?\"\n",
    "tokens_id, tokens_str, activation_cache = process_input_hf(model, auto_tokenizer, prompt)\n",
    "print(\"Tokens ID (AutoTokenizer):\", tokens_id)\n",
    "print(\"Tokens String (AutoTokenizer):\", tokens_str)\n",
    "print(len(activation_cache))\n",
    "activation = get_activation_hf(activation_cache, layer_index)\n",
    "print(f\"resid_post_mlp for layer {layer_index}:\", activation.shape if activation is not None else \"None\")\n",
    "print(activation)\n",
    "modified_recon_activations_new = activation\n",
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(error_after)\n",
    "print(mse_error_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c0653",
   "metadata": {},
   "source": [
    "### Original Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5454c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "  Candidate 1:  the (Logit: -29.919225692749023)\n",
      "  Candidate 2:  a (Logit: -30.52708625793457)\n",
      "  Candidate 3:  to (Logit: -30.872114181518555)\n",
      "  Candidate 4: , (Logit: -31.00540542602539)\n",
      "  Candidate 5: \n",
      " (Logit: -31.133556365966797)\n",
      "  Candidate 6:  you (Logit: -31.3023681640625)\n",
      "  Candidate 7: . (Logit: -31.325265884399414)\n",
      "  Candidate 8:  in (Logit: -31.418594360351562)\n",
      "  Candidate 9:  that (Logit: -31.46228790283203)\n",
      "  Candidate 10:  it (Logit: -31.574438095092773)\n",
      "\n",
      "\n",
      "Step 2:\n",
      "  Candidate 1:  a (Logit: -119.24163055419922)\n",
      "  Candidate 2:  sure (Logit: -119.3289794921875)\n",
      "  Candidate 3:  going (Logit: -119.41527557373047)\n",
      "  Candidate 4:  ready (Logit: -119.50484466552734)\n",
      "  Candidate 5:  looking (Logit: -120.21627807617188)\n",
      "  Candidate 6:  still (Logit: -120.2265396118164)\n",
      "  Candidate 7:  interested (Logit: -120.4596176147461)\n",
      "  Candidate 8:  using (Logit: -120.46378326416016)\n",
      "  Candidate 9:  in (Logit: -120.65441131591797)\n",
      "  Candidate 10:  worried (Logit: -120.6690444946289)\n",
      "\n",
      "\n",
      "Step 3:\n",
      "  Candidate 1: verted (Logit: -51.58854675292969)\n",
      "  Candidate 2: spective (Logit: -53.28206253051758)\n",
      "  Candidate 3: spect (Logit: -54.37642288208008)\n",
      "  Candidate 4: vert (Logit: -54.5172119140625)\n",
      "  Candidate 5: verts (Logit: -55.68467712402344)\n",
      "  Candidate 6: spection (Logit: -57.39292526245117)\n",
      "  Candidate 7: ? (Logit: -57.74125289916992)\n",
      "  Candidate 8: version (Logit: -57.999237060546875)\n",
      "  Candidate 9:  to (Logit: -58.08490753173828)\n",
      "  Candidate 10: - (Logit: -58.32606887817383)\n",
      "\n",
      "\n",
      "Step 4:\n",
      "  Candidate 1: ? (Logit: -74.06855010986328)\n",
      "  Candidate 2: , (Logit: -75.42339324951172)\n",
      "  Candidate 3: ?\" (Logit: -75.49243927001953)\n",
      "  Candidate 4:  or (Logit: -75.92665100097656)\n",
      "  Candidate 5:  and (Logit: -76.72173309326172)\n",
      "  Candidate 6:  enough (Logit: -77.468994140625)\n",
      "  Candidate 7:  yet (Logit: -77.6148452758789)\n",
      "  Candidate 8:  like (Logit: -78.0799789428711)\n",
      "  Candidate 9:  at (Logit: -78.23387908935547)\n",
      "  Candidate 10:  in (Logit: -78.2605209350586)\n",
      "\n",
      "\n",
      "Step 5:\n",
      "  Candidate 1: \n",
      " (Logit: -124.7516098022461)\n",
      "  Candidate 2:  Do (Logit: -126.13678741455078)\n",
      "  Candidate 3:  I (Logit: -126.33380889892578)\n",
      "  Candidate 4:  You (Logit: -126.39299774169922)\n",
      "  Candidate 5:  If (Logit: -126.39952850341797)\n",
      "  Candidate 6:  Are (Logit: -126.61884307861328)\n",
      "  Candidate 7:  What (Logit: -126.8447265625)\n",
      "  Candidate 8:  How (Logit: -126.89637756347656)\n",
      "  Candidate 9:  Then (Logit: -127.16068267822266)\n",
      "  Candidate 10:  Or (Logit: -127.1952133178711)\n",
      "\n",
      "\n",
      "Original Output: Are you introverted?\n",
      "\n",
      "I'm not. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I'm not a big introvert. I\n",
      "logits type Output:  the averted?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat_with_gpt2(model, tokens_id):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(tokens_id, max_length=100, pad_token_id=auto_tokenizer.eos_token_id)\n",
    "    response = auto_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "response = chat_with_gpt2(model, tokens_id)\n",
    "response_l, logits = chat_with_gpt2_logits(model, tokens_id, auto_tokenizer)\n",
    "chat_with_gpt2_top_k_candidates(model, tokens_id, auto_tokenizer)\n",
    "print(\"Original Output:\", response)\n",
    "print(\"logits type Output:\", response_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f10ca",
   "metadata": {},
   "source": [
    "### Controlled Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443b2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "torch.Size([1, 5, 768])\n",
      "tensor([[[ 0.9184,  0.1396,  0.4812,  ..., -1.7562, -0.2046,  0.3966],\n",
      "         [-2.3731,  0.7637, -1.3836,  ..., -1.3632, -2.3260,  0.6030],\n",
      "         [ 2.1773, -3.8999, -2.5548,  ..., -4.0262,  0.6047, -0.9181],\n",
      "         [ 3.8940,  0.6625, -2.7102,  ..., -0.2636,  4.2834,  0.9351],\n",
      "         [ 0.0863,  0.7447, -0.9693,  ..., -0.6241, -1.3438,  3.7102]]])\n",
      "tensor([[ 8491,   345, 18951, 13658,    30]])\n",
      "['Are', 'Ġyou', 'Ġintro', 'verted', '?']\n"
     ]
    }
   ],
   "source": [
    "mse_error_after, error_after = calculate_error(activation, modified_recon_activations_new)\n",
    "print(mse_error_after)\n",
    "modified_activations = modified_recon_activations_new.unsqueeze(0)\n",
    "print(modified_activations.shape)\n",
    "print(modified_activations)\n",
    "print(tokens_id)\n",
    "print(tokens_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c43646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from torch import nn\n",
    "class ModifiedGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.modified_output = None  # 用于存储第六层的原始输出\n",
    "        self.temp = GPT2Model(config=config)\n",
    "        self.ln_f = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        \n",
    "    def set_modified_output(self, output, layer_to_modify=6):\n",
    "        self.modified_output = output\n",
    "        self.layer_to_modify = layer_to_modify\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, output_hidden_states=True, **kwargs):\n",
    "        output = self.transformer(input_ids, output_hidden_states=True, **kwargs)\n",
    "        # output = super().forward(input_ids, output_hidden_states=True, **kwargs)\n",
    "        hidden_states = output[0]\n",
    "        logits_before = self.lm_head(hidden_states)\n",
    "        print(\"original final state:\", hidden_states)\n",
    "        print(\"before shape:\", logits_before.shape)\n",
    "        print(\"before:\", logits_before)\n",
    "        # 继续通过剩余的层\n",
    "        if self.modified_output is not None:\n",
    "            # 从指定层开始使用提供的激活值进行修改\n",
    "            modified_states = self.modified_output\n",
    "            for i in range(self.layer_to_modify, len(self.transformer.h)):\n",
    "                print(f\"Layer {i} original activation:\", output[2][i])\n",
    "                layer_module = self.transformer.h[i]\n",
    "                print(f\"Layer {i} modified activation:\", modified_states)\n",
    "                layer_outputs = layer_module(modified_states, attention_mask=None)  \n",
    "                modified_states = layer_outputs[0]\n",
    "                print(f\"Layer {i+1} pre-view activation:\", modified_states)\n",
    "            # 将最终输出设置为最后一层修改后的输出\n",
    "            hidden_states = modified_states\n",
    "            print(\"final state original after ln_f: \", output[2][12] )\n",
    "            print(\"final state modified before ln_f: \", hidden_states)\n",
    "            hidden_states = self.ln_f(hidden_states)\n",
    "            print(\"final state modified after ln_f: \", hidden_states)\n",
    "            # print(\"error:\",calculate_error(output[2][12], hidden_states))\n",
    "        # 输出最后一层的hidden state给LM头\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        #print(\"after shape:\", logits.shape)\n",
    "        #print(\"after:\", logits)\n",
    "        #mse, error = calculate_error(logits, logits_before)\n",
    "        #print(\"error:\",error)\n",
    "        return CausalLMOutputWithPast(logits=logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44f18912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "class ModifiedGPT2Model(GPT2LMHeadModel):\n",
    "    def __init__(self, config, layer_to_modify=6, feature_indices = [53912], feature_values = [10]):\n",
    "        super().__init__(config)\n",
    "        self.modified_output = None  # 用于存储第六层的原始输出\n",
    "        self.ln_f = GPT2Model(config=config).ln_f\n",
    "        self.feature_indices = feature_indices\n",
    "        self.feature_values = feature_values\n",
    "        self.layer_to_modify = layer_to_modify\n",
    "        \n",
    "    def set_modified_output(self, hidden_list):\n",
    "        activation = hidden_list[self.layer_to_modify][0]\n",
    "        latent_activations, recon_activations = encode_decode(autoencoder, activation)\n",
    "        mse_error, error = calculate_error(activation, recon_activations)\n",
    "        modified_recon_activations = feature_steering(autoencoder, activation, self.feature_indices, self.feature_values)\n",
    "        modified_recon_activations_new = modified_recon_activations + error\n",
    "        self.modified_output = modified_recon_activations_new.unsqueeze(0)\n",
    "        print(self.modified_output.shape)\n",
    "\n",
    "    def forward(self, input_ids, output_hidden_states=True, **kwargs):\n",
    "        output = self.transformer(input_ids, output_hidden_states=True, **kwargs)\n",
    "        final_hidden_states = output[0]\n",
    "        hidden_states_list = output[2]\n",
    "        self.set_modified_output(hidden_states_list)\n",
    "        # 继续通过剩余的层\n",
    "        if self.modified_output is not None:\n",
    "            # 从指定层开始使用提供的激活值进行修改\n",
    "            modified_states = self.modified_output\n",
    "            for i in range(self.layer_to_modify, len(self.transformer.h)):\n",
    "                layer_module = self.transformer.h[i]\n",
    "                layer_outputs = layer_module(modified_states, attention_mask=None)  \n",
    "                modified_states = layer_outputs[0]\n",
    "            # 将最终输出设置为最后一层修改后的输出\n",
    "            final_hidden_states = modified_states\n",
    "            final_hidden_states = self.ln_f(final_hidden_states)\n",
    "        # 输出最后一层的hidden state给LM头\n",
    "        logits = self.lm_head(final_hidden_states)\n",
    "        return CausalLMOutputWithPast(logits=logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03a171a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 42.9540, 79.8337,  0.0000])\n",
      "Feature 53912 modified with +10\n",
      "torch.Size([1, 5, 768])\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 42.9540, 79.8337,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +10\n",
      "torch.Size([1, 6, 768])\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 42.9540, 79.8337,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +10\n",
      "torch.Size([1, 7, 768])\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 42.9540, 79.8336,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Feature 53912 modified with +10\n",
      "torch.Size([1, 8, 768])\n",
      "original: tensor([0.0000, 0.0000, 4.2954, 7.9834, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Modified: tensor([ 0.0000,  0.0000, 42.9540, 79.8336,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000])\n",
      "Feature 53912 modified with +10\n",
      "torch.Size([1, 9, 768])\n",
      "Are you introverted? the the the the the\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "set_seed(123)\n",
    "custom_model = ModifiedGPT2Model(model.config)\n",
    "custom_model.load_state_dict(model.state_dict())  # 复制权重\n",
    "\"\"\"\n",
    "set_seed(123)\n",
    "custom_model = ModifiedGPT2Model.from_pretrained('gpt2', output_hidden_states=True, layer_to_modify=6, feature_indices = [53912], feature_values = [10])\n",
    "inputs = auto_tokenizer.encode(\"Are you introverted?\", return_tensors=\"pt\")\n",
    "generated_text_ids = custom_model.generate(inputs, max_length=10, pad_token_id=auto_tokenizer.eos_token_id)\n",
    "generated_text = auto_tokenizer.decode(generated_text_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dda4a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified_output is setted\n",
      "this is layer 6: tensor([[[ 9.1928e+02,  1.3977e+02,  4.8171e+02,  ..., -1.7579e+03,\n",
      "          -2.0484e+02,  3.9704e+02],\n",
      "         [-2.3754e+03,  7.6445e+02, -1.3850e+03,  ..., -1.3646e+03,\n",
      "          -2.3283e+03,  6.0361e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6380e+01,  7.4543e+02, -9.7030e+02,  ..., -6.2472e+02,\n",
      "          -1.3452e+03,  3.7139e+03]]])\n",
      "this is layer 7: tensor([[[ 9.1925e+02,  1.3994e+02,  4.8160e+02,  ..., -1.7579e+03,\n",
      "          -2.0491e+02,  3.9693e+02],\n",
      "         [-2.3752e+03,  7.6522e+02, -1.3857e+03,  ..., -1.3639e+03,\n",
      "          -2.3272e+03,  6.0387e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6013e+01,  7.4588e+02, -9.7125e+02,  ..., -6.2456e+02,\n",
      "          -1.3436e+03,  3.7126e+03]]])\n",
      "this is layer 7: tensor([[[ 9.1925e+02,  1.3994e+02,  4.8160e+02,  ..., -1.7579e+03,\n",
      "          -2.0491e+02,  3.9693e+02],\n",
      "         [-2.3752e+03,  7.6522e+02, -1.3857e+03,  ..., -1.3639e+03,\n",
      "          -2.3272e+03,  6.0387e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6013e+01,  7.4588e+02, -9.7125e+02,  ..., -6.2456e+02,\n",
      "          -1.3436e+03,  3.7126e+03]]])\n",
      "this is layer 8: tensor([[[ 9.1930e+02,  1.4006e+02,  4.8156e+02,  ..., -1.7577e+03,\n",
      "          -2.0495e+02,  3.9680e+02],\n",
      "         [-2.3759e+03,  7.6535e+02, -1.3865e+03,  ..., -1.3644e+03,\n",
      "          -2.3264e+03,  6.0386e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.3885e+01,  7.4616e+02, -9.7113e+02,  ..., -6.2586e+02,\n",
      "          -1.3436e+03,  3.7095e+03]]])\n",
      "this is layer 8: tensor([[[ 9.1930e+02,  1.4006e+02,  4.8156e+02,  ..., -1.7577e+03,\n",
      "          -2.0495e+02,  3.9680e+02],\n",
      "         [-2.3759e+03,  7.6535e+02, -1.3865e+03,  ..., -1.3644e+03,\n",
      "          -2.3264e+03,  6.0386e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.3885e+01,  7.4616e+02, -9.7113e+02,  ..., -6.2586e+02,\n",
      "          -1.3436e+03,  3.7095e+03]]])\n",
      "this is layer 9: tensor([[[ 9.1916e+02,  1.4021e+02,  4.8140e+02,  ..., -1.7575e+03,\n",
      "          -2.0488e+02,  3.9660e+02],\n",
      "         [-2.3774e+03,  7.6425e+02, -1.3869e+03,  ..., -1.3638e+03,\n",
      "          -2.3239e+03,  6.0262e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.4024e+01,  7.4514e+02, -9.6745e+02,  ..., -6.2255e+02,\n",
      "          -1.3378e+03,  3.7076e+03]]])\n",
      "this is layer 9: tensor([[[ 9.1916e+02,  1.4021e+02,  4.8140e+02,  ..., -1.7575e+03,\n",
      "          -2.0488e+02,  3.9660e+02],\n",
      "         [-2.3774e+03,  7.6425e+02, -1.3869e+03,  ..., -1.3638e+03,\n",
      "          -2.3239e+03,  6.0262e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.4024e+01,  7.4514e+02, -9.6745e+02,  ..., -6.2255e+02,\n",
      "          -1.3378e+03,  3.7076e+03]]])\n",
      "this is layer 10: tensor([[[ 9.1902e+02,  1.4049e+02,  4.8093e+02,  ..., -1.7575e+03,\n",
      "          -2.0453e+02,  3.9638e+02],\n",
      "         [-2.3767e+03,  7.6413e+02, -1.3871e+03,  ..., -1.3629e+03,\n",
      "          -2.3226e+03,  6.0352e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.0573e+01,  7.4665e+02, -9.6818e+02,  ..., -6.2066e+02,\n",
      "          -1.3287e+03,  3.7107e+03]]])\n",
      "this is layer 10: tensor([[[ 9.1902e+02,  1.4049e+02,  4.8093e+02,  ..., -1.7575e+03,\n",
      "          -2.0453e+02,  3.9638e+02],\n",
      "         [-2.3767e+03,  7.6413e+02, -1.3871e+03,  ..., -1.3629e+03,\n",
      "          -2.3226e+03,  6.0352e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.0573e+01,  7.4665e+02, -9.6818e+02,  ..., -6.2066e+02,\n",
      "          -1.3287e+03,  3.7107e+03]]])\n",
      "this is layer 11: tensor([[[ 9.1866e+02,  1.4206e+02,  4.7868e+02,  ..., -1.7592e+03,\n",
      "          -2.0387e+02,  3.9633e+02],\n",
      "         [-2.3680e+03,  7.6130e+02, -1.3852e+03,  ..., -1.3676e+03,\n",
      "          -2.3189e+03,  6.0774e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 7.0786e+01,  7.4312e+02, -9.8376e+02,  ..., -6.1045e+02,\n",
      "          -1.3150e+03,  3.7104e+03]]])\n",
      "modified_output is setted\n",
      "this is layer 6: tensor([[[ 9.1928e+02,  1.3977e+02,  4.8171e+02,  ..., -1.7579e+03,\n",
      "          -2.0484e+02,  3.9704e+02],\n",
      "         [-2.3754e+03,  7.6445e+02, -1.3850e+03,  ..., -1.3646e+03,\n",
      "          -2.3283e+03,  6.0361e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6380e+01,  7.4543e+02, -9.7030e+02,  ..., -6.2472e+02,\n",
      "          -1.3452e+03,  3.7139e+03]]])\n",
      "this is layer 7: tensor([[[ 9.1925e+02,  1.3994e+02,  4.8160e+02,  ..., -1.7579e+03,\n",
      "          -2.0491e+02,  3.9693e+02],\n",
      "         [-2.3752e+03,  7.6522e+02, -1.3857e+03,  ..., -1.3639e+03,\n",
      "          -2.3272e+03,  6.0387e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6013e+01,  7.4588e+02, -9.7125e+02,  ..., -6.2456e+02,\n",
      "          -1.3436e+03,  3.7126e+03]]])\n",
      "this is layer 7: tensor([[[ 9.1925e+02,  1.3994e+02,  4.8160e+02,  ..., -1.7579e+03,\n",
      "          -2.0491e+02,  3.9693e+02],\n",
      "         [-2.3752e+03,  7.6522e+02, -1.3857e+03,  ..., -1.3639e+03,\n",
      "          -2.3272e+03,  6.0387e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.6013e+01,  7.4588e+02, -9.7125e+02,  ..., -6.2456e+02,\n",
      "          -1.3436e+03,  3.7126e+03]]])\n",
      "this is layer 8: tensor([[[ 9.1930e+02,  1.4006e+02,  4.8156e+02,  ..., -1.7577e+03,\n",
      "          -2.0495e+02,  3.9680e+02],\n",
      "         [-2.3759e+03,  7.6535e+02, -1.3865e+03,  ..., -1.3644e+03,\n",
      "          -2.3264e+03,  6.0386e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.3885e+01,  7.4616e+02, -9.7113e+02,  ..., -6.2586e+02,\n",
      "          -1.3436e+03,  3.7095e+03]]])\n",
      "this is layer 8: tensor([[[ 9.1930e+02,  1.4006e+02,  4.8156e+02,  ..., -1.7577e+03,\n",
      "          -2.0495e+02,  3.9680e+02],\n",
      "         [-2.3759e+03,  7.6535e+02, -1.3865e+03,  ..., -1.3644e+03,\n",
      "          -2.3264e+03,  6.0386e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.3885e+01,  7.4616e+02, -9.7113e+02,  ..., -6.2586e+02,\n",
      "          -1.3436e+03,  3.7095e+03]]])\n",
      "this is layer 9: tensor([[[ 9.1916e+02,  1.4021e+02,  4.8140e+02,  ..., -1.7575e+03,\n",
      "          -2.0488e+02,  3.9660e+02],\n",
      "         [-2.3774e+03,  7.6425e+02, -1.3869e+03,  ..., -1.3638e+03,\n",
      "          -2.3239e+03,  6.0262e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.4024e+01,  7.4514e+02, -9.6745e+02,  ..., -6.2255e+02,\n",
      "          -1.3378e+03,  3.7076e+03]]])\n",
      "this is layer 9: tensor([[[ 9.1916e+02,  1.4021e+02,  4.8140e+02,  ..., -1.7575e+03,\n",
      "          -2.0488e+02,  3.9660e+02],\n",
      "         [-2.3774e+03,  7.6425e+02, -1.3869e+03,  ..., -1.3638e+03,\n",
      "          -2.3239e+03,  6.0262e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.4024e+01,  7.4514e+02, -9.6745e+02,  ..., -6.2255e+02,\n",
      "          -1.3378e+03,  3.7076e+03]]])\n",
      "this is layer 10: tensor([[[ 9.1902e+02,  1.4049e+02,  4.8093e+02,  ..., -1.7575e+03,\n",
      "          -2.0453e+02,  3.9638e+02],\n",
      "         [-2.3767e+03,  7.6413e+02, -1.3871e+03,  ..., -1.3629e+03,\n",
      "          -2.3226e+03,  6.0352e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.0573e+01,  7.4665e+02, -9.6818e+02,  ..., -6.2066e+02,\n",
      "          -1.3287e+03,  3.7107e+03]]])\n",
      "this is layer 10: tensor([[[ 9.1902e+02,  1.4049e+02,  4.8093e+02,  ..., -1.7575e+03,\n",
      "          -2.0453e+02,  3.9638e+02],\n",
      "         [-2.3767e+03,  7.6413e+02, -1.3871e+03,  ..., -1.3629e+03,\n",
      "          -2.3226e+03,  6.0352e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 8.0573e+01,  7.4665e+02, -9.6818e+02,  ..., -6.2066e+02,\n",
      "          -1.3287e+03,  3.7107e+03]]])\n",
      "this is layer 11: tensor([[[ 9.1866e+02,  1.4206e+02,  4.7868e+02,  ..., -1.7592e+03,\n",
      "          -2.0387e+02,  3.9633e+02],\n",
      "         [-2.3680e+03,  7.6130e+02, -1.3852e+03,  ..., -1.3676e+03,\n",
      "          -2.3189e+03,  6.0774e+02],\n",
      "         [ 4.7753e+08, -3.5279e+08, -5.1653e+06,  ..., -7.6302e+07,\n",
      "           1.4349e+09,  6.0882e+08],\n",
      "         [ 9.0576e+08, -6.6914e+08, -9.7951e+06,  ..., -1.4472e+08,\n",
      "           2.7217e+09,  1.1548e+09],\n",
      "         [ 7.0786e+01,  7.4312e+02, -9.8376e+02,  ..., -6.1045e+02,\n",
      "          -1.3150e+03,  3.7104e+03]]])\n",
      "Step 1:\n",
      "  Candidate 1:  the (Logit: -29.919225692749023)\n",
      "  Candidate 2:  a (Logit: -30.52708625793457)\n",
      "  Candidate 3:  to (Logit: -30.872114181518555)\n",
      "  Candidate 4: , (Logit: -31.00540542602539)\n",
      "  Candidate 5: \n",
      " (Logit: -31.133556365966797)\n",
      "  Candidate 6:  you (Logit: -31.3023681640625)\n",
      "  Candidate 7: . (Logit: -31.325265884399414)\n",
      "  Candidate 8:  in (Logit: -31.418594360351562)\n",
      "  Candidate 9:  that (Logit: -31.46228790283203)\n",
      "  Candidate 10:  it (Logit: -31.574438095092773)\n",
      "\n",
      "\n",
      "Step 2:\n",
      "  Candidate 1:  a (Logit: -119.24163055419922)\n",
      "  Candidate 2:  sure (Logit: -119.3289794921875)\n",
      "  Candidate 3:  going (Logit: -119.41527557373047)\n",
      "  Candidate 4:  ready (Logit: -119.50484466552734)\n",
      "  Candidate 5:  looking (Logit: -120.21627807617188)\n",
      "  Candidate 6:  still (Logit: -120.2265396118164)\n",
      "  Candidate 7:  interested (Logit: -120.4596176147461)\n",
      "  Candidate 8:  using (Logit: -120.46378326416016)\n",
      "  Candidate 9:  in (Logit: -120.65441131591797)\n",
      "  Candidate 10:  worried (Logit: -120.6690444946289)\n",
      "\n",
      "\n",
      "Step 3:\n",
      "  Candidate 1: verted (Logit: -51.58854675292969)\n",
      "  Candidate 2: spective (Logit: -53.28206253051758)\n",
      "  Candidate 3: spect (Logit: -54.37642288208008)\n",
      "  Candidate 4: vert (Logit: -54.5172119140625)\n",
      "  Candidate 5: verts (Logit: -55.68467712402344)\n",
      "  Candidate 6: spection (Logit: -57.39292526245117)\n",
      "  Candidate 7: ? (Logit: -57.74125289916992)\n",
      "  Candidate 8: version (Logit: -57.999237060546875)\n",
      "  Candidate 9:  to (Logit: -58.08490753173828)\n",
      "  Candidate 10: - (Logit: -58.32606887817383)\n",
      "\n",
      "\n",
      "Step 4:\n",
      "  Candidate 1: ? (Logit: -74.06855010986328)\n",
      "  Candidate 2: , (Logit: -75.42339324951172)\n",
      "  Candidate 3: ?\" (Logit: -75.49243927001953)\n",
      "  Candidate 4:  or (Logit: -75.92665100097656)\n",
      "  Candidate 5:  and (Logit: -76.72173309326172)\n",
      "  Candidate 6:  enough (Logit: -77.468994140625)\n",
      "  Candidate 7:  yet (Logit: -77.6148452758789)\n",
      "  Candidate 8:  like (Logit: -78.0799789428711)\n",
      "  Candidate 9:  at (Logit: -78.23387908935547)\n",
      "  Candidate 10:  in (Logit: -78.2605209350586)\n",
      "\n",
      "\n",
      "Step 5:\n",
      "  Candidate 1: \n",
      " (Logit: -124.7516098022461)\n",
      "  Candidate 2:  Do (Logit: -126.13678741455078)\n",
      "  Candidate 3:  I (Logit: -126.33380889892578)\n",
      "  Candidate 4:  You (Logit: -126.39299774169922)\n",
      "  Candidate 5:  If (Logit: -126.39952850341797)\n",
      "  Candidate 6:  Are (Logit: -126.61884307861328)\n",
      "  Candidate 7:  What (Logit: -126.8447265625)\n",
      "  Candidate 8:  How (Logit: -126.89637756347656)\n",
      "  Candidate 9:  Then (Logit: -127.16068267822266)\n",
      "  Candidate 10:  Or (Logit: -127.1952133178711)\n",
      "\n",
      "\n",
      "logits type Steered Output:  the averted?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generated_text_l, logits = chat_with_gpt2_logits(custom_model, inputs, auto_tokenizer)\n",
    "chat_with_gpt2_top_k_candidates(custom_model, inputs, auto_tokenizer)\n",
    "print(\"logits type Steered Output:\", generated_text_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
