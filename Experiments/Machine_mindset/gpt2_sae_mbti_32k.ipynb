{
 "cells": [
  {
   "cell_type": "code",
   "id": "3a264bdc49ea2966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:45:04.416233Z",
     "start_time": "2024-07-21T01:44:57.878613Z"
    }
   },
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "# 导入库\n",
    "import torch\n",
    "import blobfile as bf\n",
    "import transformer_lens\n",
    "import sparse_autoencoder\n",
    "from experiments.utils import update_json_file, update_numpy_file\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2ae2db09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:45:04.446731Z",
     "start_time": "2024-07-21T01:45:04.418235Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import re\n",
    "# 加载模型\n",
    "def load_model(model_name, center_writing_weights=False):\n",
    "    model = transformer_lens.HookedTransformer.from_pretrained(model_name, center_writing_weights=center_writing_weights)\n",
    "    device = next(model.parameters()).device\n",
    "    return model, device\n",
    "\n",
    "# 处理输入\n",
    "def process_input(model, prompt):\n",
    "    tokens_id = model.to_tokens(prompt)  # (1, n_tokens)\n",
    "    tokens_str = model.to_str_tokens(prompt)\n",
    "    with torch.no_grad():\n",
    "        logits, activation_cache = model.run_with_cache(tokens_id, remove_batch_dim=True)\n",
    "    return tokens_id, tokens_str, activation_cache\n",
    "\n",
    "# 提取激活\n",
    "def get_activation(activation_cache, layer_index=6, location=\"resid_post_mlp\"):\n",
    "    transformer_lens_loc = {\n",
    "        \"mlp_post_act\": f\"blocks.{layer_index}.mlp.hook_post\",\n",
    "        \"resid_delta_attn\": f\"blocks.{layer_index}.hook_attn_out\",\n",
    "        \"resid_post_attn\": f\"blocks.{layer_index}.hook_resid_mid\",\n",
    "        \"resid_delta_mlp\": f\"blocks.{layer_index}.hook_mlp_out\",\n",
    "        \"resid_post_mlp\": f\"blocks.{layer_index}.hook_resid_post\",\n",
    "    }[location]\n",
    "    return activation_cache[transformer_lens_loc]\n",
    "\n",
    "# 加载自编码器\n",
    "def load_autoencoder(location, layer_index, device):\n",
    "    with bf.BlobFile(sparse_autoencoder.paths.v5_32k(location, layer_index), mode=\"rb\") as f:\n",
    "        state_dict = torch.load(f)\n",
    "        autoencoder = sparse_autoencoder.Autoencoder.from_state_dict(state_dict)\n",
    "        autoencoder.to(device)\n",
    "    return autoencoder\n",
    "\n",
    "# 编码和解码激活张量\n",
    "def encode_decode(autoencoder, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        latent_activations, info = autoencoder.encode(input_tensor)\n",
    "        reconstructed_activations = autoencoder.decode(latent_activations, info)\n",
    "    return latent_activations, reconstructed_activations\n",
    "\n",
    "# 计算误差并打印结果\n",
    "def calculate_normalized_mse(input_tensor, reconstructed_activations):\n",
    "    normalized_mse = (reconstructed_activations - input_tensor).pow(2).sum(dim=1) / (input_tensor).pow(2).sum(dim=1)\n",
    "    return normalized_mse\n",
    "\n",
    "def extract_activations(prompt, tokens, latent_activations, top_k=32, activation_threshold=3):\n",
    "    activations_dict = {}\n",
    "    prompt_key = prompt  # 根据需要设置不同的 prompt 标识符\n",
    "\n",
    "    total_activations_count = 0\n",
    "    \n",
    "    # 遍历所有 feature\n",
    "    for feature_index in range(latent_activations.shape[1]):\n",
    "        # 获取该 feature 的所有激活值\n",
    "        feature_activations = latent_activations[:, feature_index]\n",
    "        \n",
    "        # 仅提取 top k 非零激活值\n",
    "        non_zero_activations = feature_activations[(feature_activations != 0) & (feature_activations >= activation_threshold)]\n",
    "        if non_zero_activations.numel() == 0:\n",
    "            continue\n",
    "        top_k_values, top_k_indices = torch.topk(non_zero_activations, min(top_k, non_zero_activations.numel()))\n",
    "\n",
    "        # 构建特征激活字典\n",
    "        feature_key = f\"Feature {feature_index}\"\n",
    "        activations_dict[feature_key] = {prompt_key: {}}\n",
    "        for value, index in zip(top_k_values, top_k_indices):\n",
    "            nonzero_indices = (feature_activations == value).nonzero(as_tuple=True)\n",
    "            if len(nonzero_indices[0]) == 1:  # 确保只有一个元素\n",
    "                token_index = nonzero_indices[0].item()\n",
    "                token = tokens[token_index]\n",
    "                activations_dict[feature_key][prompt][token] = value.item()\n",
    "            else:\n",
    "                print(f\"Skipping ambiguous token index: {nonzero_indices}\")\n",
    "\n",
    "        total_activations_count += len(top_k_values)\n",
    "\n",
    "    # Print the total number of activations extracted\n",
    "    print(f\"Total activations extracted: {total_activations_count}\")\n",
    "\n",
    "    # Optionally, return the total number of activations\n",
    "    return activations_dict\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d048903c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T01:45:32.373688Z",
     "start_time": "2024-07-21T01:45:04.448763Z"
    }
   },
   "source": [
    "model, device = load_model(\"gpt2\")\n",
    "layer_index = 6\n",
    "location = \"resid_post_mlp\"\n",
    "autoencoder = load_autoencoder(location, layer_index, device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "153365d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T14:48:00.156699Z",
     "start_time": "2024-07-20T14:48:00.142526Z"
    }
   },
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "output_folder = f'output/{today}'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-20T14:48:13.109347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置路径\n",
    "prompt_folder_path = 'dataset/prompt_1000_pro_2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# 遍历所有 .parquet 文件\n",
    "for file_name in os.listdir(prompt_folder_path):\n",
    "    count = 1\n",
    "    if file_name.endswith('.parquet'):\n",
    "        prompt_file_path = os.path.join(prompt_folder_path, file_name)\n",
    "        data = pd.read_parquet(prompt_file_path)\n",
    "        for index, row in data.iterrows():\n",
    "            print(f\"current file: {prompt_file_path}\")\n",
    "            prompt_id = row['prompt_id']\n",
    "            prompt = row['prompt']\n",
    "            tokens_id, tokens_str, activation_cache = process_input(model, prompt)\n",
    "            activation = get_activation(activation_cache, layer_index)\n",
    "            latent_activations, reconstructed_activations = encode_decode(autoencoder, activation)\n",
    "\n",
    "            print(latent_activations.shape)\n",
    "            print(activation.shape)\n",
    "            print(reconstructed_activations.shape)\n",
    "            non_zero_count = (latent_activations != 0).sum().item()\n",
    "            print(\"Non-zero activation count:\", non_zero_count)\n",
    "            print(f\"This is {count}/1000 prompt\")\n",
    "            count+=1\n",
    "            activations_dict = extract_activations(prompt_id, tokens_str, latent_activations, top_k=5)\n",
    "            \n",
    "            activations_file_name = file_name.replace('.parquet', '_1000_activation_pro_2.json')\n",
    "            activations_file_path = os.path.join(output_folder, activations_file_name)\n",
    "            \n",
    "            update_json_file(activations_file_path, activations_dict)"
   ],
   "id": "f829e42434afbfe3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file: dataset/prompt_1000_pro_2\\decision_feeling.parquet\n",
      "torch.Size([174, 32768])\n",
      "torch.Size([174, 768])\n",
      "torch.Size([174, 768])\n",
      "Non-zero activation count: 5568\n",
      "This is 1/1000 prompt\n",
      "Total activations extracted: 557\n",
      "current file: dataset/prompt_1000_pro_2\\decision_feeling.parquet\n",
      "torch.Size([184, 32768])\n",
      "torch.Size([184, 768])\n",
      "torch.Size([184, 768])\n",
      "Non-zero activation count: 5888\n",
      "This is 2/1000 prompt\n",
      "Total activations extracted: 569\n",
      "current file: dataset/prompt_1000_pro_2\\decision_feeling.parquet\n",
      "torch.Size([225, 32768])\n",
      "torch.Size([225, 768])\n",
      "torch.Size([225, 768])\n",
      "Non-zero activation count: 7200\n",
      "This is 3/1000 prompt\n",
      "Total activations extracted: 709\n",
      "current file: dataset/prompt_1000_pro_2\\decision_feeling.parquet\n",
      "torch.Size([95, 32768])\n",
      "torch.Size([95, 768])\n",
      "torch.Size([95, 768])\n",
      "Non-zero activation count: 3040\n",
      "This is 4/1000 prompt\n",
      "Total activations extracted: 335\n",
      "current file: dataset/prompt_1000_pro_2\\decision_feeling.parquet\n",
      "torch.Size([217, 32768])\n",
      "torch.Size([217, 768])\n",
      "torch.Size([217, 768])\n",
      "Non-zero activation count: 6944\n",
      "This is 5/1000 prompt\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34d46b1f26cf7b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T16:23:41.388513Z",
     "start_time": "2024-07-18T16:23:41.349436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from output/2024-07-18\\activations_fi_50.npy:\n",
      "            Feature  Index SubIndex     Value\n",
      "0         Feature 4      1    times  1.321357\n",
      "1         Feature 6      1     hear  4.202684\n",
      "2        Feature 11      1           1.179202\n",
      "3        Feature 35      1      not  1.101583\n",
      "4        Feature 42      1   posted  0.736671\n",
      "...             ...    ...      ...       ...\n",
      "19995  Feature 4875     19      own  1.515423\n",
      "19996  Feature 4875     19       to  1.373387\n",
      "19997  Feature 4875     19      him  1.207780\n",
      "19998  Feature 4875     19       my  0.862682\n",
      "19999  Feature 4875     19           0.751266\n",
      "\n",
      "[20000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_numpy_file(filename):\n",
    "    # 读取 NumPy 文件中的数据\n",
    "    try:\n",
    "        data = np.load(filename, allow_pickle=True).item()\n",
    "        df = pd.DataFrame(data)\n",
    "        print(f\"Data from {filename}:\")\n",
    "        print(df.head(20000))  # 打印前几行数据\n",
    "    except (FileNotFoundError, OSError):\n",
    "        print(f\"File {filename} not found or could not be read.\")\n",
    "\n",
    "# 示例调用\n",
    "read_numpy_file(activations_file_path)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:11:05.707190Z",
     "start_time": "2024-07-21T02:11:05.585047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = 'Pretend you’re a perceiving person to answer the question.'\n",
    "tokens_id, tokens_str, activation_cache = process_input(model, prompt)\n",
    "tokens_str"
   ],
   "id": "3d37eca8957e1414",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " 'P',\n",
       " 'ret',\n",
       " 'end',\n",
       " ' you',\n",
       " '�',\n",
       " '�',\n",
       " 're',\n",
       " ' a',\n",
       " ' perce',\n",
       " 'iving',\n",
       " ' person',\n",
       " ' to',\n",
       " ' answer',\n",
       " ' the',\n",
       " ' question',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64ea5e528bc214eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
